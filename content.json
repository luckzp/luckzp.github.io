[{"title":"架构设计原则","date":"2021-04-06T02:03:58.000Z","path":"2021/04/06/架构设计原则/","text":"1.架构设计考虑的方面 扩展性（伸缩性） 可用性 可靠性 一致性 负载均衡 过载保护 灾难恢复和备份","tags":[]},{"title":"Netty初识","date":"2021-03-31T10:40:18.000Z","path":"2021/03/31/Netty初识/","text":"1.Netty 定义。Netty is an asynchronous event-driven network application frameworkfor rapid development of maintainable high performance protocol servers &amp; clients. 2.为什么不用 Java 的 NIO 库而用 Netty。（抛出问题，用 netty 解决问题。）编写代码复杂。传统的库要基于 Socket 进行基本的 I/O 操作（bind()、connect()、read()和 write()）依赖于底层网络传输所提供的原语。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class NioClient &#123; private static Selector selector = null; public void start(String ip, int port) throws IOException &#123; //创建选择器 selector = Selector.open(); //打开监听通道 SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); //连接对应的服务器 ip , port socketChannel.connect(new InetSocketAddress(ip, port)); //注册select为连接状态 socketChannel.register(selector, SelectionKey.OP_CONNECT); System.out.println(&quot;客户端，启动成功...&quot;); &#125; public void listen() throws IOException &#123; while (true) &#123; //阻塞方法，轮询注册的channel,当至少一个channel就绪的时候才会继续往下执行 selector.select(); //获取就绪的SelectionKey Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = keys.iterator(); SelectionKey key = null; //迭代就绪的key while (it.hasNext()) &#123; key = it.next(); it.remove(); //SelectionKey相当于是一个Channel的表示，标记当前channel处于什么状态 // 按照channel的不同状态处理数据 process(key); &#125; &#125; &#125; private void process(SelectionKey key) throws IOException &#123; //channel处于可连接状态，发送消息给服务端 if (key.isConnectable()) &#123; System.out.println(&quot;connect事件就绪 ....&quot;); SocketChannel clientChannel = (SocketChannel) key.channel(); if (clientChannel.isConnectionPending()) &#123; clientChannel.finishConnect(); &#125; clientChannel.configureBlocking(false); String name = UUID.randomUUID().toString(); System.out.println(&quot;客户端发送数据：&#123;&#125;&quot; + name); ByteBuffer buffer = ByteBuffer.wrap(name.getBytes()); clientChannel.write(buffer); clientChannel.register(key.selector(), SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; //获取对应的socket System.out.println(&quot;read事件就绪 ....&quot;); SocketChannel socket = (SocketChannel) key.channel(); //设置一个读取数据的Buffer 大小为1024 ByteBuffer buff = ByteBuffer.allocate(1024); StringBuilder content = new StringBuilder(); int len = socket.read(buff); if (len &gt; 0) &#123; buff.flip(); content.append(new String(buff.array(), &quot;utf-8&quot;)); //让客户端读取下一次read System.out.println(&quot;客户端收到反馈：&quot; + content); key.interestOps(SelectionKey.OP_READ); &#125;else if(len &lt;= 0)&#123; key.cancel(); socket.close(); &#125; &#125; &#125; public static void main(String[] args) throws IOException &#123; NioClient client = new NioClient(); client.start(&quot;localhost&quot;,8080); client.listen(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839public class EchoClient &#123; private final String host; private final int port; public EchoClient(String host, int port) &#123; this.host = host; this.port = port; &#125; public static void main(String[] args) throws Exception &#123; String host = &quot;127.0.0.1&quot;; int port = 8080; new EchoClient(host, port).start(); &#125; public void start() throws Exception &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group); b.channel(NioSocketChannel.class); b.handler(new ClientHandlerInitializer()); // 连接服务器 Channel ch = b.connect(host, port).sync().channel(); // 接受系统输入 BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); // 连续输入 while (true) &#123; String line = in.readLine(); if (line == null) // 如果是空行, 则跳过本次循环, 不输出 continue; ch.writeAndFlush(line + &quot;\\r\\n&quot;); &#125; &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 不同的 IO 有不同的网络 APINetty 为它所有的传输实现提供了一个通用 API 3.用 Netty 实现 NIO,BIO,AIO。NIO 的性能最好，实际上 linux 内核并不支持 aio，通过 epoll(true/false)来区分 nio 或者 aio。4.Netty 在其他方面的应用。Dubbo,Zookeeper,Redission5.Netty 与 OOM。 6.核心组件。Channel-SocketChannel 是一个连接，可以看作是传入（入站）或者传出（出站）数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。ChaneelFuture-异步通知Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。为此，Netty 提供了ChannelFuture 接口，其 addListener()方法注册了一个 ChannelFutureListener，以便在某个操作完成时（无论是否成功）得到通知。关于 ChannelFuture 的更多讨论 可以将 ChannelFuture 看作是将来要执行的操作的结果的占位符。它究竟 什么时候 被执行则可能取决于若干的因素，因此不可能准确地预测，但是可以肯定的是它 将会 被执行。此外，所有属于同一个 Channel 的操作都被保证其将以它们被调用的顺序被执行。EventLoop-控制，多线程处理，并发。EventLoop 与 EventGroupLoopChannelHandler，ChannelPipeline 和 ChannelHandlerContextChannelHandler从应用程序开发人员的角度来看，Netty 的主要组件是 ChannelHandler，它充当了所有处理入站和出站数据的应用程序逻辑的容器。Netty 以适配器类的形式提供了大量默认的 ChannelHandler,帮我们简化了开发。ChannelPipeline提供了 ChannelHandler 链的容器，并定义了用于在该链上传播入站和出站事件流的 API。当 Channel 被添加到 ChannelPipeline 时，将会被分配一个ChannelHandlerContext的关系，代表 ChannelHandler 和 ChannelPipeline 的关系。ByteBuf网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐。Netty 的 ByteBuffer 替代品是 ByteBuf ，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。7.TCP 粘包拆包以及解决方案TCP 粘包/拆包发⽣的原因（1）应⽤程序 write 写⼊的字节⼤⼩⼤于套接⼝发送缓冲区⼤⼩；（2）进⾏ MSS（Maxitum Segment Size 最⼤分段⼤⼩）⼤⼩的 TCP 分段；（3）以太⽹帧的 payload ⼤于 MTU（Maxitum Transmission Unit 最⼤传输单元）进⾏ IP 分⽚。粘包问题的解决策略（1）消息定⻓，例如每个报⽂的⼤⼩为固定⻓度 200 字节，如果不够，空位补空格；（2）在包尾增加回⻋换换符进⾏分割，例如 FTP 协议；（3）将消息分为消息头和消息体，消息头中包含表示消息总⻓度（或者消息体⻓度）的字段，通常设计思想为消息头的⼀个字段使⽤ int32 来表示消息的总⻓度；（4）更复杂的应⽤层协议。8.Netty 应用以 RocketMQ 为例​","tags":[]},{"title":"排查现网问题分析","date":"2021-03-06T14:04:12.000Z","path":"2021/03/06/排查现网问题分析/","text":"吞吐量（TPS，QPS）：按时段考虑。并发：按时刻考虑。 1.查看日志报错 too many connection，Mysql 连接数爆了。 查询当前 Mysql 连接数和设置的最大连接数。 查询是否有慢查询。 2.数据库 CPU 使用率过高 SQL 查询频率很高，qps 是否过高。 SQL 未走到索引，导致扫描行数过多，甚至全表扫描。 开启 MySQL 慢查询的步骤 在 my.cnf 的[mysqld]配置下，修改一下参数 1234567#启用记录慢SQL功能slow_query_log &#x3D; 1#设置超过1秒的SQL为慢SQLlong_query_time &#x3D; 1#记录慢sql日志路径Slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql-slow.log重启mysql服务，让配置生效 开启 mongo 慢查询日志 123456781).mongodb慢查询日志是否开启：db.getProfilingLevel();2).0为关闭慢查询，1开启慢查询，2记录全部查询命令：设置慢查询状态为1，时长&gt;100ms：db.setProfilingLevel(1,100);3).返回最近的10条慢查询：db.system.profile. find ().limit(10). sort (&#123; ts : -1 &#125;).pretty();根据日志做出判断1).不合理的索引关键字：IXSCAN、keysExamined；若keysExamined (扫描索引建的记录数)大于nreturned(返回结果的记录数)，需要考虑优化索引；2).全表扫描关键字：COLLSCAN、docsExamined，记录中涉及全表扫描； 3.QPS 有规律波动 tcp 的全连接队列与半连接队列被占满。 TCP 连接不够用。 启动 TCP 快速回收。 修改 linuxTCP 相关配置其中 net.ipv4. tcp_max_syn_backlog 为半连接队列长度，net.core.somaxconn 为全连接队列长度，这两个值要足够大。","tags":[]},{"title":"应对连环炮","date":"2021-02-21T02:38:08.000Z","path":"2021/02/21/应对连环炮/","text":"HashSet 的底层实现说下？内置 HashMap,将加入的元素作为 HashMap 的 key。说下 HashMap 的数据结构，为什么 loadFactor 是 0.75？数组+红黑树，0.75 是 HashMap 空间和时间的权衡，提高 loadFactor 会降低空间的开销，但是会增加查询时间的开销（get 和 put）。为什么要高位参与与运算？这其实也是扰动函数，为了降低哈希码的冲突。右位移 16 位，正好是 32bit 的一半，高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。为什么它的 size 是 2 的 n 次方？因为对 key 的 hashCode 进行扰动函数处理之后，是根据（n-1）&amp; hash 判断元素在数组中的位置的。为什么默认是 16？讲下它的扩容机制。遍历数组，然后遍历数组链表，从链表头到尾，保留 next = e.next;先计算出节点在新 hashmp 的数组位置 i，然后用头插法将节点插入到新数组的头结点（e.next = new B）。e = next; do while(e != null)之后的一样。什么时候转红黑树，为什么要转红黑树？为什么它是线程不安全的，它的哪些方法是线程不安全的？Put 的时候会导致数据会覆盖为什么会造成死循环？1.8 是如何解决这个问题的？它的线程安全的实现有什么？ConcurrentHashMap 和 HashTable 有什么区别？说下它 1.7 和 1.8 的实现是什么？有什么区别？为什么要这么做？为什么说 ConcurrentHashMap 是线程安全的？它的 get 操作是有锁的吗？它是强一致性的吗？它为什么是弱一致性的？ get 操作全程不需要加锁是因为 Node 的成员 val 是用 volatile 修饰的和数组用 volatile 修饰没有关系。 数组用 volatile 修饰主要是保证在数组扩容的时候保证可见性。 弱一致性，get 方法只能保证看到之前完成的操作，无法保证看到正在进行中的操作。 ConcurrentHashMap 1.7 和 1.8 是如何扩容的？sizeCtl 参数是干什么的，讲讲变换过程？为什么要用 volatile 修饰？说说它的功能？,这个关键字只是告诉编译器这个变量是易变的,每次使用该变量时都要重新从内存读取。什么是 MESI 协议？多核 cpu 保证 cache 一致性CPU 原语是什么？什么是可见性？可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。JMM 说说是什么？为什么要有 JMM？所有的变量都存储在主内存中，每个线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读取主内存中的变量。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。Happened-before 是什么？它和 synchronized 的区别是什么？前一个操作的结果对后续操作时可见的。synchronized：锁的升级与降级说下是什么？自旋锁是什么？偏向锁是什么？Mark-Word 说下？锁的粒度是什么？锁消除了解吗？锁会被合并吗？什么时候会发生？锁消除：对于被检测出不可能存在竞争的共享数据的锁进行消除。(逃逸分析)锁粗化:虚拟机探测到一系列连续操作都对同一个对象加锁解锁，就将加锁的范围粗化到整个操作系列的外部。偏向锁：当锁对象第一次被线程获取的时候，进入偏向状态，标记为 101，同时 CAS 将线程 ID 进入到对象头的 Mark Word 中，如果成功，这个线程以后每次获取锁就不再需要进行同步操作，甚至 CAS 不都需要。当另一个线程尝试获取这个锁，偏向状态结束，恢复到未锁定状态或者轻量级状态。轻量级锁：对象头的内存布局 Mark Word,有个 tag bits,记录了锁的四种状态:无琐状态，偏向锁状态，轻量级锁状态，重量级锁状态.轻量级锁相对重量级锁而言，使用 CAS 去避免重量级锁使用互斥量的开销。线程尝试获取锁时，如果锁处于无琐状态，先采用 CAS 去尝试获取锁，如果成功，锁状态更新为轻量级锁状态。如果有两条以上的线程争用一个锁，状态重为重量级锁。你刚才说了 CAS，你能说下它是什么东西吗？为什么要引入 CAS？ABA 问题是如何解决的？AQS 了解吗？它是如何实现的？CLH 又是什么？CLH,是虚拟的双向队列，即不存在队列实例，仅存在节点与节点之间的 pre 和 next 关系。AQS 将每条请求共享资源的线程封装成一个 CLH 锁队列的一个节点来实现锁的分配。ReentrantLock 和 synchronized 区别是什么？为什么 ReetrantLock 能实现公平锁？默认构造器是公平锁吗？为什么不是？两者都是可重入锁(自己可以再次获取自己的内部锁)，锁计数器加 1;synchronized 只能是是非公平锁，而 ReenTrantLock 默认实现非公平锁，也支持公平锁(先等先得)synchronized 依赖于 JVM 实现，而 ReenTrantLock 是基于 JDK 实现的;ReenTrantLock 功能加多：1、等待可中断，2、支持公平锁，3、基于 Condition 实现选择性唤醒;Copy-on-Write 了解吗？Fork/Join 又是什么？什么是线程，什么是协程？你刚才说了管程？你能说下这几个到底是做什么的吗？线程池说下参数，四种内置的拒绝策略，以及它的执行流程。你用过吗？为什么要这么设置参数？I/O 密集型应用和计算密集型应用如何设置其参数？你具体的业务线程池的参数是怎么设计的？为什么？测过吗？你定制化开发过吗？线程池预留了 3 个供子类扩展的方法你知道是哪三个吗？能做什么你知道吗？ThreadLocal 是什么？它为什么会造成内存泄漏？你实际开发中用到过吗？Spring 事务用这个干什么的？Spring 事务管理通过使用 ThreadLocal，解除了事务管理模块与数据访问层的紧密耦合，提高了模块的可重用性，也保证了多线程环境下的对 connection 资源的有效管理，实现了线程安全。什么是 Spring 事务的 SavePoint？保存点，记录操作的当前位置，之后可以回滚到指定的位置你知道死锁吗？如何解决死锁？产生死锁的原因主要是：（1） 因为系统资源不足。（2） 进程运行推进的顺序不合适。（3） 资源分配不当等。死锁的必要条件： 互斥条件（Mutual exclusion）：资源不能被共享，只能由一个进程使用。 请求与保持条件（Hold and wait）：已经得到资源的进程可以再次申请新的资源。非剥夺条件（No pre-emption）：已经分配的资源不能从相应的进程中被强制地剥夺。循环等待条件（Circular wait）：系统中若干进程组成环路，改环路中每个进程都在等待相邻进程正占用的资源。sleep 和 wait 的区别是什么？BIO、NIO、AIO 是什么？说下区别，以及如何使用？了解 Netty 吗？如何解决粘包问题？ChannelPipeline 又是什么？ByteBuf 知道吗？读写指针又是什么？为什么要用它，解决了 NIO 类库的 ByteBuffer 什么问题？它和 mina 的区别是什么？它的 Zero-Copy？了解过 FastThreadLocal 吗？它为什么比 ThreadLocal 快？有看过其中源码吗？Netty 解决了 NIO 类库的什么问题？空轮询又是什么？RPC 又是什么？序列化和反序列化又是什么？几个核心抽象说下。是干什么的？讲讲 Netty 的线程模型。 你说你了解虚拟机，你知道虚拟机的运行时数据区吗？哪些是线程共享的，哪些是线程独有的？线程私有的：程序计数器虚拟机栈本地⽅法栈线程共享的：堆⽅法区直接内存 (⾮运⾏时数据区的⼀部分)你了解 JVM 调优吗？调优过吗？为什么要这么设置？垃圾回收算法有几种？为什么要分代收集？⽐如在新⽣代中，每次收集都会有⼤量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。⽽⽼年代的对象存活⼏率是⽐较⾼的，⽽且没有额外的空间对它进⾏分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进⾏垃圾收集。Young 区说说它的分布结构，为什么 Eden 区 80%？为什么大对象直接进入老年代？控制的参数是什么？一个对象如果不是大对象，怎样才能进入老年代？控制的参数是什么？什么时候会发生 OOM？你遇到过吗？怎么解决的？为什么低版本的 JDK 要把永久代内存调大点？默认大小是多少你知道吗？什么是 Major GC，什么是 Minor GC？什么情况下会频繁 GC？你查看过 GC 日志吗？什么时候回收对象？引用计数和可达性分析是什么？为什么 Java 使用后者？Python 使用前者？什么是 GCRoot？什么类型的对象可以作为 GCRoot？什么时候对象不可达？Java 的四种引用说下，分别用在什么场景？你知道 JDK 源码哪里有用到 WeakReference 吗？什么是 STW？什么是 Safepoint？类加载的过程说下，什么时候优化，以及不同的阶段的主要优化是什么？解语法糖是什么时候？为什么在编译的时候解语法糖？什么是双亲委派模型？可以破坏吗？各个 ClassLoader 加载哪部分类的？你自定义过 ClassLoader 吗？你说你用过 Jstack 诊断 CPU 使用率飙升的情况，说下具体步骤？Arthas 用过吗？Class 文件格式说下，什么是魔数，Class 文件的魔数是什么？JMX 了解吗？生产上有碰到过虚拟机的问题吗？怎么解决的？ ACID 说下是什么，如何实现的？Atomicity Consistency Isolation Durability你说你优化过 SQL，怎么优化的说下。like ‘%xx%’，like ‘%xx’，like ‘xx%’ 哪种情况会用到索引，为什么？说下 MySQL 执行流程。WAL(Write-Ahead Logging) 知道吗？redo log 和 undo log 是什么，它们作用说下。你说你改过 buffer_pool_size 等参数，为什么要改它？它里面的数据结构说下是什么？为什么冷热 3:7？join_buffer 你说你也改了，为什么？什么是驱动表和被驱动表？如何优化？你说你建了索引，什么是蔟集索引，什么是非蔟集索引？什么是回表？什么时候会索引失效？你的二级索引什么用得多？为什么优先使用普通索引，而不是唯一索引？MySQL 会死锁吗？什么是间隙锁？它会导致什么问题？MVCC 说下是什么？4 种事务说下是什么？哪种或者哪几种事务隔离级别能避免幻读？能避免脏读？你说你还开启了 binlog，能说说是什么吗？binlog 有几种格式？你选的是哪个？为什么？canal 用过吗？说说它的原理。MySQL 主从模式如何开启？你是如何优化 SQL 的？上亿级别的数据你是如何优化分页的？为什么不建议在 MySQL 中使用分区机制？几个主要的线程说下它们是什么？做什么的？MySQL 读写了解吗？如何实现的？能做到强一致性吗？为什么？为什么删了数据还是磁盘空间不变？自增主键用完了会怎么样？如何解决这个问题？自增主键什么时候是不连续的？这样做的好处是什么？为什么推荐用自增主键？B+ Tree 又是什么？如何迁移数据库？为什么不建议使用外键？在高版本的 MySQL 中 count(1) 和 count(*) 区别是什么？order by 是如何工作的？分页机制又是什么？ACL 和 RBAC 是什么？PBAC 和 ABAC 知道吗说下？grant 之后一定要刷新吗？视图用过吗？它的作用说下。视图和表的区别说下。存储过程写过吗？存储函数和存储过程的区别说下。为什么要分库分表？分库分表如何做到动态缩容/扩容？NoSQL 用过吗？OceanBase 了解吗？HBase 了解吗？HBase 有哪些坑，你碰到过吗？什么是 RegionServer？什么时候用 NoSQL，它能取代 RDBMS 吗？你说你用过 Elasticsearch，能说下它的请求执行过程吗？它的总体架构说下，画一下。它的插件你用过吗？你们的分词策略是什么？倒排索引说下是什么。 线程和进程说下区别？线程的几种状态说下。Java 中的线程和操作系统的线程关系？动态内存分配和回收策略是什么？什么是空闲列表和指针碰撞？具体用什么数据结构存的？什么时候用它们？空闲列表四种策略说下。Page Cache 知道吗，说说它的作用。Redis 和 Kafka 中间件如何通过 Page Cache 来优化？哪些类型会导致内存泄漏？TCP 和 HTTP 是什么？它们之间的关系说下。OSI 七层是哪七层？分别是干什么的？TCP 和 UDP 区别是什么？什么时候会导致 TCP 抖动？TCP 是如何保证稳定的？我就要用 UDP，如何使它和 TCP 一样能保证数据到达？CPU 是如何执行任务的？你知道 numa 架构吗？哪些中间件可以通过这个来怎么优化？为什么绑核能优化？什么是 Zero-Copy？你用的中间件中有哪些用到了这个特性？内核态和用户态是什么？硬件你了解过吗？什么是 x86？什么是 ARM？你说精简指令集？它精简了什么？ARM 架构的 CPU 是什么样的？画一下。M1 芯片为什么这么快，有了解吗？5G 有了解吗？有点题外话了，最后问你个问题，你说你是软件通信工程，通信学的什么？选修了什么？通信是学硬件吗？光纤为什么这么快？8 根线和 4 根线区别？傅立叶变换说下是什么？数字信号模拟信号？你大学在班级定位？前几？ Redis 它的 5 种基础类型和 6 个数据结构说下。String、List、Set、Hash、ZSet 和简单动态字符串，链表，字典，跳跃表，整数集合，压缩列表。HyperLogLog、BitMap、GEO、Stream 有接触过吗？什么时候用这些特殊数据结构？跳表又是什么，画一下？为什么使用跳表？跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。跳跃表通常是有序集合的底层实现之一，表中的节点按照分值大小进行排序。1、由很多层结构组成；2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的 head 节点和后面的 nil 节点；3、最底层的链表包含了所有的元素；4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；为什么不用红黑树？全局 Hash 表又是什么？如何扩容的？什么是渐进式 rehash？Redis 怎么做到的？IO 多路复用是什么？多路是什么？复用了什么？AOF 和 RDB 又是什么？为什么 Redis 没有实现 WAL 机制？AOF 持久化策略有哪三种？你们是怎么选的？AOF 什么时候重写？为什么重写？主从复制用到了哪种日志？主从复制过程说下。主从复制什么时候增量，什么时候全量？第一次连接时，网络中断了怎么办？Redis 主从是什么？主从从又是什么？为什么主从从可以减少主库压力？从库可以设置可写吗？从库可写会带来什么问题？主从什么时候会导致数据丢失？Redis 十万并发能支撑住吗？如何支撑十万以上并发？为什么操作大对象支持不了十万并发？Redis Cluster 是什么？ 你说到了 CRC16，你知道一致性哈希算法吗，能说下是什么吗？你说虚拟节点，说下如何实现？Codis 了解吗？你们的 Redis 集群方案是什么？Redis 是如何保证高可用的？哨兵机制了解吗？什么是主观下线什么是客观下线？选主的四个筛选条件优先级的条件依次递减分别是什么？打分又是什么？如何打分？缓存击穿、缓存雪崩、缓存穿透说下？如何解决？布隆过滤器又是什么？能手写个布隆过滤器吗？数据倾斜知道吗，如何解决？分布式锁了解过吗？讲讲分布式锁实现原理？Redisson 源码看过吗？它是如何实现的分布式锁？Lua 脚本保证原子性吗？分布式锁需要注意哪四个问题？Redis 事务说下。缓存污染知道是什么吗？如何淘汰数据的？分别是哪八种策略？Redis 对 lru 做了什么改变吗？lfu 又是什么？Redis 做了什么优化？Redis 多线程是什么多线程？默认开启吗？你们生产中用了吗？Redis 6 还有什么新特性？自定义过 Redis 数据类型吗？自定义过 Redis 命令吗？如何解决数据库和缓存数据不一致问题？Pika 知道吗？Tendis 和它的区别？如何实现一个 Key 千万并发？（这个有个群的群友的 Zoom 面试题） 消息中间件解决了哪几个问题？简单介绍下你用的 Kafka。从 Topic -&gt; Record&lt;Key,Value&gt; -&gt; Producer -&gt; acks -&gt; Interceptor -&gt; Broker -&gt; Page Cache -&gt; Controller -&gt; Coordinator -&gt; Partition -&gt; Replica -&gt; Leader Replica -&gt; Follower Replica -&gt; ISR -&gt; Unclean Leader Election -&gt; Consumer -&gt; Consumer Group -&gt; Consumer Offset -&gt; Consumer Group Offset -&gt; Idempotence -&gt; Transaction -&gt; Rebalance -&gt; High Watermark -&gt; Log Deletion -&gt; Leader Epoch -&gt; LEO -&gt; Zero Copy -&gt; Consumer Heartbeat -&gt; Zookeeper 到这结束。它和 RocketMQ、RabbitMQ 有什么区别？什么时候消息会丢失？Producer 网络抖动后，它的消息在哪存着，内存还是磁盘还是哪里？Producer 和 Consumer 什么时候建立的 TCP 连接？为什么这么做？Consumer 为什么要采取 pull 的方式？Producer 为什么采用 push 的方式？为什么用 TCP 不用 HTTP？高水位、LEO 是什么？Lead Epoch 知道吗？幂等性是如何实现的？说下 Kafka 事务，Kafka 事务实现的事务隔离级别？什么时候触发 Rebalance？如何避免？如何指定发送消息到指定 Partition？消息交付可靠性保障承诺三个说下，以及 Kafka 是如何实现它们的？哦，你说精准一次，怎么实现的？根据消息数以及消息大小，计算需要多少磁盘容量和带宽。Kafka 的 JVM 参数调优说下。 JMS 了解吗？RabbitMQ:1、如何保证消息的可靠性传输（如何处理消息丢失的问题）？1）生产者弄丢了数据：可以开启 confirm 模式，每次写的消息都会分配一个唯一的 id，然后如果写入了 rabbitmq 中，rabbitmq 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 rabbitmq 没能处理这个消息，会回调你一个 nack 接口，告诉你这个消息接收失败，你可以重试。confirm 机制是异步的。2）rabbitmq 弄丢了数据，开启 rabbitmq 的持久化，就是消息写入之后会持久化到磁盘。创建 queue 的时候将其设置为持久化的，发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 rabbitmq 就会将消息持久化到磁盘上去。而且持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了。3）消费端弄丢了数据：手动调用 rabbitmq 提供的 ack 机制。每次你自己代码里确保处理完的时候，再程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack？那 rabbitmq 就认为你还没处理完，这个时候 rabbitmq 会把这个消费分配给别的 consumer 去处理。2、保证消息是有顺序的；拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。3、消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？可能你的消费端出了问题，不消费了。先修复 consumer 的问题，确保其恢复消费速度，临时紧急扩容，将 queue 资源和 consumer 资源扩大，增加消费能力，等快速消费完积压数据之后，得恢复原先部署架构。rabbitmq，rabbitmq 是可以设置过期时间的，就是 TTL，大量积压在 mq 里，而是大量的数据会直接搞丢。批量重导，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。4、如何保证消息不被重复消费啊保证消息队列消费的幂等性就不怕，重复消费无所谓。主要是结合业务来谈：如写数据库，先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。如果是写 redis，那没问题了，反正每次都是 set，天然幂等性。如果是下订单，让生产者发送每条数据的时候，里面加一个全局唯一的 id，根据 ID 查询是否消费过了，如果已经处理，就忽视。5、RabbitMQ 高可用性：rabbitmq 有三种模式：单机模式，普通集群模式，镜像集群模式。单击模式，一个节点。普通集群，多台机器上启动多个 rabbitmq 实例，每个机器启动一个。但是你创建的 queue，只会放在一个 rabbtimq 实例上，但是每个实例都同步 queue 的元数据。实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。没做到所谓的分布式。镜像集群模式: 你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了。Spring Bean Scope 说下。Spring 的注入方式有几种，为什么推荐用构造器注入？@Resource 和 @Autowired 区别说下。什么是 IoC 和 AOP？Spring 解决了什么？@Bean 和 @Component 区别说下。Spring Bean 的生命周期说下。Spring AOP 原理，各种 Advice 和 Advisor 说下。AOP 的两种代理方式是什么？AOP 一般作用说下。三级缓存解决循环依赖的过程说下。Spring 的事务传播行为说下。Spring 事务隔离级别说下。Spring 事务实现原理。Spring 用到了哪些设计模式，能分别讲讲它是如何实现的吗，具体是哪些类？BeanFactory 和 ApplicationContext 说下区别。说下 BeanFactory 和 FactoryBean 区别？BeanPostProcessor 和 BeanFactoryPostProcessor 区别是什么？Spring 事件知道吗？Spring 如何自定义 xml 解析？各种 Smart 开头的 Bean 的前置处理器，什么时候被调用，你知道吗？Spring Cache 是如何实现的？Spring Data JPA 呢？ 注解扫描如何实现的，你能手写个吗？写过 Spring 的插件吗？如何实现的？代码开源了吗？ Spring MVC 执行流程说下。@RestController 和 @Controller 区别说下。怎么取得 URL 中的 { } 里面的变量？Spring MVC 和 Struts2 比有什么优点？Spring MVC 怎么样设定重定向和转发的？说下 Spring MVC 的常用注解。如何解决 POST 请求中文乱码问题，GET 的又如何处理呢？Interceptor 和 Filter 区别？Spring MVC 的异常处理 ？怎样在方法里面得到 Request，或者 Session？Spring MVC 中函数的返回值是什么？怎么样把 ModelMap 里面的数据放入 Session 里面？Spring MVC 的控制器是不是单例模式,如果是,有什么问题,怎么解决？Spring MVC 的 RequestMapping 的方法是线程安全的吗？为什么？介绍下 WebApplicationContext。跨域问题如何解决？如何解决全局异常？validation 有了解吗？用过吗？Json 处理如何实现的？哦，你刚才说了父子容器，能讲讲什么是父子容器吗？Spring MVC 国际化有了解过吗？怎么实现的 Spring Boot 是如何实现自动装配的？运行 Spring Boot 有几种方式？Spring Boot Starter 工作原理。Spring Boot 核心注解说下。@Enable 类型注解是如何实现的？@Conditional 类型注解呢？自定义过吗？说下异步调用@Async。什么是 YAML？Spring Boot Profiles 如何实现的？ bootstrap.properties 和 application.properties 说下区别。Spring Boot 事件和 Spring 事件有什么关系？Spring Boot Actuator 了解过吗？说一下。Spring Batcher 用过吗，说下。Spring Boot 是如何实现内嵌 Servlet 容器的，在哪行代码启动的？Spring Boot 完美实现了模块化编程，你认同吗？ Spring Boot 的核心注解是哪个：@SpringBootApplication，他包含了三个注解：@SpringBootConfiguration：组合了 @Configuration注解，实现配置文件的功能。从 Spring3.0，@Configuration 用于定义配置类，可替换 xml 配置文件，被注解的类内部包含有一个或多个被@Bean 注解的方法，这些方法将会被 AnnotationConfigApplicationContext 或 AnnotationConfigWebApplicationContext 类进行扫描，并用于构建 bean 定义，初始化 Spring 容器。*@SpringBootConfiguration也是来源于**@Configuration，二者功能都是将当前类标注为配置类，并将当前类里以 @Bean 注解标记的方法的实例注入到 srping 容器中，实例名即为方法名。**@ComponentScan：Spring 组件扫描。用于将一些标注了特定注解的 bean 定义批量采集注册到 Spring 的 IoC 容器之中，这些特定的注解大致包括：@Controller@Entity@Component@Service@Repository@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项。**@EnableAutoConfiguration注解启用自动配置，其可以帮助 SpringBoot 应用将所有符合条件的 @Configuration 配置都加载到当前 IoC 容器之中，\\*6、开启 Spring Boot 特性有哪几种方式？1）继承 spring-boot-starter-parent 项目 2）导入 spring-boot-dependencies 项目依赖SpringBoot 内置 Tomcat/Jetty 容器，可以独立运行。8、运行 Spring Boot 有哪几种方式？1）打包用命令或者放到容器中运行3）直接执行 main 方法运行2）用 Maven/ Gradle 插件运行Spring Boot 自动配置原理是什么？扫描所有具有 META-INF/spring.factories 的 jar 包。spring-boot-autoconfigure-x.x.x.x.jar 里就有一个这样的 spring.factories 文件。这个 spring.factories 文件也是一组一组的 key=value 的形式，其中一个 key 是 EnableAutoConfiguration 类的全类名，而它的 value 是一个 xxxxAutoConfiguration 的类名的列表，这些类名以逗号分隔。这个@EnableAutoConfiguration 注解通过@SpringBootApplication 被间接的标记在了 Spring Boot 的启动类上。在 SpringApplication.run(…)的内部就会执行 selectImports()方法，找到所有 JavaConfig 自动配置类的全限定名对应的 class，然后将所有自动配置类加载到 Spring 容器中。SpringBoot 启动的时候会通过@EnableAutoConfiguration 注解找到 META-INF/spring.factories 配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以 AutoConfiguration 结尾来命名的，它实际上就是一个 JavaConfig 形式的 Spring 容器配置类，它能通过以 Properties 结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而 XxxxProperties 类是通过@ConfigurationProperties 注解与全局配置文件中对应的属性进行绑定的。StartersStarters 可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。Starters 包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。 Spring Cloud Netflix 听说你了解。画一下 Spring Cloud Netflix 架构图。说说 Eureka 默认多少秒发送心跳？增量还是全量？CP 还是 AP？如何防止脑裂的？二级缓存知道吗？Eureaka 的自我保护模式说下。ServiceInstance 和 DiscoryClient 知道吗？是干嘛的？分布式事务除了两段提交，还有什么实现方式？哦，你说 Saga，Saga 你说下是什么？Ribbon 是什么说一下，它解决了什么问题？Feign 又是什么？它和 Ribbon 什么关系？Dubbo 和 Feign 区别？Dubbo 的 SPI 知道吗？Zuul 是什么？它和 Nginx 有什么区别？除了 Zuul 还有什么网关可选？Hystrix 是什么？它是如何实现的？熔断、降级和限流他们的区别说一下。Hystrix 信号量机制，隔离策略细粒度控制如何做的？看过源码吗？你优化过吗？微服务十一点说一下分别是什么？分布式配置中心有哪些？你们用的 Apollo 还是 Spring Config 还是其他的？为什么？服务监控有了解吗？什么是幂等？如何实现接口幂等？如何实现分布式 Session？有更好的方法吗？哦，你说了 JWT，能详细说下吗？不同系统的间授权的 OAuth2 了解吗？ MyBatis 了解吗？一级缓存，二级缓存？# 和 $ 说下。如何实现的动态 SQL？ORM 是什么？和 Hibernate 区别？MyBatis 工作原理？MyBatis 都有哪些 Executor 执行器？它们之间的区别是什么？MyBatis 中如何指定使用哪一种 Executor 执行器？模糊查询 like 语句该怎么写？MyBatis 是否支持延迟加载？如果支持，它的实现原理是什么？MyBatis 如何执行批量操作？SqlSessionFactoryBean 是什么？如何实现和 Spring 的整合的？Mapper 方法可以重载吗？为什么不可以？MyBatis 是如何将 SQL 执行结果封装为目标对象并返回的？都有哪些映射形式？哦，你说简单封装了 JDBC，说下 JDBC 几个重要的类。为什么要预编译？有什么好处吗？ Nginx 了解吗，说下其优缺点？怎么实现 Nginx 集群？什么是反向代理？和正向代理区别是什么？Tomcat 和 Nginx 区别？限流怎么做的，有哪三种？令牌桶和漏斗算法是什么，区别是什么？如何在其之上使用 Lua 脚本？有几种负载均衡策略？你们生产上用的哪个？为什么？为什么 Nginx 性能这么高？有没有更高的？F5 又是什么？Nginx 是怎么处理请求的？Nginx 目录有哪些？nginx.conf 配置过吗？有哪些属性模块？静态资源放哪？虚拟主机配置？location 说下。location 语法说下。 Tomcat 你也了解？什么是 Tomcat 的 Connector？Service、Connector、Container 介绍下它们。详细说下它们是如何处理请求的，能画下它们的架构图吗？如何部署的？一定要放到 webapps 目录下吗？在哪配置？为什么不用 Jetty？区别是什么？Servlet 是线程安全的吗？为什么？怎样让它线程安全？Servlet 初始化过程？init 方法什么时候调用？Servlet 什么时候第一次初始化？JSP 知道吗？有几个内置对象？你说 JSP 是特殊的 Servlet，你看过源码吗？JSP 如何热部署的？EL 表达式知道吗？如何实现的？（大四某打车集团非滴滴校招的时候被问到的） 云原生了解吗？云原生十二要素说下。Cloud Foundry 平台你知道吗？HeroKu？Kong？ 哦？你说是六边形架构？你说下什么是六边形架构？整洁架构呢？它们之间的区别？分层架构了解吗？MVP、MVC 架构说下。负载均衡算法七种说下。如何实现一个秒杀系统。一定不会超卖吗？如何解决？什么是 SOA？什么是微服务？以及两者的区别。什么是事件驱动架构？CAP 和 BASE 说下是什么？最终一致性和人弱一致性什么关系？画一下你们系统的整体架构图。QPS 和 TPS？你们的 QPS 是多少知道吗？压测过吗？说下点击网页的请求过程。哦，你说你是蓝绿部署，什么是蓝绿部署？什么是金丝雀发布？如何实现？ Docker 你也用？怎么构建 Docker 镜像？Docker 和虚拟机的区别？Docker 好处说下？Kubernetes 你也知道，说下它的组成结构？etcd 是什么？为什么不用 Zookeeper？pod 又是什么？你们生产上怎么用的？如何控制滚动更新过程？ 你说你知道 DDD？能简单说下吗？你们代码落地了吗？是如何拆分服务的？事件风暴又是什么？你们有 Code Review 吗？具体规矩？领域事件是什么？子域、通用域、核心域、支撑域、限界上下文、聚合、聚合根、实体、值对象又是什么？你们有 EventBus 吗？如何使用的？ 实际编程题 给二叉树后序和中序遍历，写前序遍历。手写个快排。翻转一下链表。O(1) 空间复杂度找出链表有环。DFS 找出二叉树搜索树第 k 大节点（这些都真的碰过了）。 实现一个多线程类，并用该线程类实例化 3 个线程 A,B,C；A 线程打印字符 A,B 线程打印字符 B，C 线程打印字符 C；启动这 3 个线程，要求启动线程的顺序为 C 线程-&gt;B 线程-&gt;A 线程，并且最后输出内容为：A B C。禁止使用 sleep 函数。 阿里应该还有各种多线程打印的问题，这个得准备。就是想拿个 6，太难了。这些只是最最最基础的内容。 接下来应该是更高级的算法题目，至少是 LeetCode Menium 难度的，翻转链表确实有点初级，练个半个小时就搞定了。暂时还没碰到，碰到我也挂了。应该是动态规划，滑动窗口，字符串的问题，手写 O(1) 时间复杂度的 LRU，回溯，贪心。 还有一种就是，你们目前技术的缺点是什么？如何优化？有没有更好的优化方案？换作是你，你会怎么做（滴滴面试，不按八股文套路来）？业务量突然增长几十倍，你怎么做？如何架构演进？你有架构设计过吗？你带过新人吗？怎么做的？ UML 类图？时序图？流程图？泳道图？甘特图？你用的什么工具？ 你平时是怎么学习一门新技术的？ 最近有看书吗？看的什么书？技术类的，能和我讲讲吗？ 你为什么离职？（回答工资问题，领导不好的都会挂）下一家公司的期望是什么？期望薪资？你的职业发展规划？你为什么要这个数字的工资？","tags":[]},{"title":"问答录","date":"2020-12-28T15:07:55.000Z","path":"2020/12/28/问答录/","text":"性价比高并仅仅指的是价格便宜的，相反价格贵也可以是性价比高。比如 4,5K 的 iphone 和 1,2K 的安卓手机。 价格便宜并不能成为护城河，降低价格是一个企业的核武器，最好不要用。 仓位管理仓位越重，对情绪也影响也越大。投资 60%的现金总资产（注意是现金，不包括房贷，车贷），就算亏完了，也不影响生活。入手基金分为 3 份，一份做持股资金，一份做波段备用金，一份做应急救援金（出现黑天鹅的情况）。 沉没成本放弃可以规避历史成本的干扰，重新展开思考：假如我现在空仓，我会愿意现价买入这只股票吗？ 伴随着财富的增加，人的各种劣根性也会显现：骄奢淫逸、心浮气躁、狂妄自大。学习的过程是让内心平静，保持正直、真诚、勤奋、节俭、谦卑、善待身边人这些好的品格常驻心间。 介意别人比你赚钱更快，是一种不可饶恕的罪行。嫉妒是种愚蠢的行为，它是你唯一不可能从中得到任何乐趣的心理活动。它只会带来很多痛苦，毫无乐趣可言，为什么要去那么干呢？——查理.芒格","tags":[]},{"title":"二叉树前序、中序、后序遍历相互求法","date":"2020-09-16T13:10:04.000Z","path":"2020/09/16/二叉树前序、中序、后序遍历相互求法/","text":"前序遍历: GDAFEMHZ 中序遍历: ADEFGHMZ 画树求法：第一步，根据前序遍历的特点，我们知道根结点为 G 第二步，观察中序遍历 ADEFGHMZ。其中 root 节点 G 左侧的 ADEF 必然是 root 的左子树，G 右侧的 HMZ 必然是 root 的右子树。 第三步，观察左子树 ADEF，左子树的中的根节点必然是大树的 root 的 leftchild。在前序遍历中，大树的 root 的 leftchild 位于 root 之后，所以左子树的根节点为 D。 第四步，同样的道理，root 的右子树节点 HMZ 中的根节点也可以通过前序遍历求得。在前序遍历中，一定是先把 root 和 root 的所有左子树节点遍历完之后才会遍历右子树，并且遍历的左子树的第一个节点就是左子树的根节点。同理，遍历的右子树的第一个节点就是右子树的根节点。 第五步，观察发现，上面的过程是递归的。先找到当前树的根节点，然后划分为左子树，右子树，然后进入左子树重复上面的过程，然后进入右子树重复上面的过程。最后就可以还原一棵树了。该步递归的过程可以简洁表达如下： 1 确定根,确定左子树，确定右子树。 2 在左子树中递归。 3 在右子树中递归。 4 打印当前根。 那么，我们可以画出这个二叉树的形状： 那么，根据后序的遍历规则，我们可以知道，后序遍历顺序为：AEFDHZMG.","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://luckzp.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"AVL和红黑树","date":"2020-09-16T02:10:52.000Z","path":"2020/09/16/AVL和红黑树/","text":"AVL 平衡二叉搜索树定义：平衡二叉树或为空树,或为如下性质的二叉排序树:（1）左右子树深度之差的绝对值不超过 1;（2）左右子树仍然为平衡二叉树.平衡因子 BF=左子树深度－右子树深度.平衡二叉树每个结点的平衡因子只能是 1，0，-1。若其绝对值超过 1，则该二叉排序树就是不平衡的。如图所示为平衡树和非平衡树示意图： RBT 红黑树AVL 是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多；红黑是弱平衡的，用非严格的平衡来换取增删节点时候旋转次数的降低；所以简单说，搜索的次数远远大于插入和删除，那么选择 AVL 树，如果搜索，插入删除次数几乎差不多，应该选择 RB 树。 红黑树上每个结点内含五个域，color，key，left，right，p。如果相应的指针域没有，则设为 NIL。一般的，红黑树，满足以下性质，即只有满足以下全部性质的树，我们才称之为红黑树：1）每个结点要么是红的，要么是黑的。2）根结点是黑的。3）每个叶结点，即空结点（NIL）是黑的。4）如果一个结点是红的，那么它的俩个儿子都是黑的。5）对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点。下图所示，即是一颗红黑树：","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://luckzp.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"自我提升总结","date":"2020-09-12T04:20:24.000Z","path":"2020/09/12/自我提升总结/","text":"说明：文章是基于结构性思维写出的，下图将文章进行高度概括，详细内容可见全文（选择性阅读即可）。 序言随着公司的规模的扩大，应届生的数量也逐渐增长。然而，从学校刚进入公司的我们，难免会有多多少少的不适应。我们如何能尽快的适应职场环境和更好的成长了？上个星期，公司特与智联教育学院合作，为我们制定了为期 5 天的培训课程，取得了非常好的效果。 结论在这 5 天的培训课程中，使我的认知、沟通和思考方式得以提升。 1. 学校到职场的转变1.1 个人与团队 在学校更多的是以个体为单位，我们以自我为中心去上课，心情不好就直接翘课，没有约束。在公司更多是以团队为单位，自己的服务的客户会影响整个团队的绩效，自己写的代码会影响整个团队的开发效率。自己做的事情将不再再仅仅影响个人，还会影响整个团队。同时，个人积极的作用会带动起整个团队，反之，则会拖团队的后退。 1.2 兴趣与职业 学生的生活更多是凭借自己的兴趣与情绪，我们往往会对自己感兴趣的课程认真听讲，而对无聊乏味的课程则在下面玩手机。但是在公司，我们从事相应的职业，是为他人服务，形成绩效。这是我们职责所在而不在是凭借兴趣，并且我们应当从追求快乐转变为追求责任。 1.3 思维与行动 学生的思维都很活跃，新点子层出不穷。学校中学习知识，往往是以训练思维为主，注重的是成绩。而在公司，是需要将我们的思维转换为产品，将知识转为绩效，注重的是可行性和商业价值。 1.4 性格自知 通过性格色彩测试，了解自己，改变自己。人生嘛，本就是一场提升心智的旅程。 2.时间管理2.1 重要紧急理论 我们生活中所碰到的事情可以分为以下四类： 重要且紧急—立刻亲自处理 重要但不紧急（这一点最重要）—计划性处理 紧急但不重要—授权委任 不重要且不紧急—当作没看见 2.2 为什么重要但不紧急的事是最需要关注的了？ 我们在生活中会遇到这种场景，每天都很忙碌。但忙完一阵子会发现，自己都不知道在忙什么了，然后心里有时候会安慰自己：反正我没有在玩，我在忙就行了。静下心来就会觉得我们是在沉溺于这种虚幻的充实满足感，做事时依靠的是自己的偏好和外界压力。根据重要紧急理论分析，这种情况就是一直在做重要且紧急的事情和紧急但不重要的事情。为了解除这种困境，对于重要且紧急的事情尽量减少，重要但不紧急的是通过列清单（To do list）来解决。重要但不紧急的事情则要规划好，有了规划，就知道了自己昨天完成了什么，今天在做什么，明天要干什么。每完成规划中的一个阶段，都可以明确知道，还可以知道距离多久能完成这个规划。其本质就是让规划的事情可视化。 3.目标管理3.1 目标分析法 说到目标也是说白了也是要规划，要对目标有全局的考虑。最常见的误区是碰到一件事时拿起来就干；订下目标后，一来就开始朝着目标前进。可以根据鱼骨分析法按照先整体后细节对目标进行分解，根据 SMART 原则制定出具体的（Specific），可测量的（Measurable ），可达到的（Attainable），相关的（Relevant），有时间的（Time based ）的目标。当目标产生冲突时，根据目标矩阵发来选择最优解。通过上述 3 种方法，这样会清楚的知道自己要按照怎样的流程来朝着目标前进。 3.2 三个 Flag a.四周时间看完剩下的《SpringBoot微信点餐系统》 b.每天中午休息时间看5分钟的书 c.每天10个深蹲 4.结构性思维有时候我说话会了一堆，可是很多人还是不明白。其背后的主要原因是自己没有想清楚，就开口说了，想到哪里就说到哪里。结构性思维会是很好的解决方法。结构性思维是采用的总分形式，其结构就像高中的议论文一样。先进行背景介绍（即序言）提出主要观点，然后对其展开并进行论证。在与他人沟通时，会想的清楚，说的明白。让听者也会清楚的知道你想表达的意思。 5.高品质沟通每个人来自不同的地方，成长于不同的环境。当然两人会对一件事情会有不同的看法。当双方都怀着：你听我的，你听我的！这种心态来沟通，想必双方彼此都不能了解对方的想法，甚至可能会导致不愉快的事情出现。如果将”你听我的“转换成”我知道了你的观点，我的观点“，同时想一下对方所说的话其原因是什么？最终彼此都会很好的知道了对方的想法。 6.心态管理6.1 心态的三驾马车 我们平常所说的心态，其具体表现形式是认知，情感，行为。这三者相辅相存，互相影响。例如：当做一件事情时，我们觉得很无聊，接着就会想到这件事没有意义，最终结果就是不去做这件事情。我们再细想一下这个情景：如果当感到无聊的时，我们想到的是做这件事情可以磨砺我们，使我们成长，其最终结果是我们把这件事做完。 同样的事情，认知的不同产生了不同的结果。这让我想到 ABC 理论。 6.2 情绪 ABC 理论 情绪 ABC 理论框架：A（Antecedent）指事情的前因，C（Consequence）指事情的后果，有前因必有后果，但是有同样的前因 A，产生了不一样的后果 C1 和 C2。这是因为从前因到后果之间，一定会透过一座桥梁 B（Bridge），这座桥梁就是认知和我们对情境的评价与解释。又因为，同一情境之下（A），不同的人的认知以及评价与解释不同（B1 和 B2），所以会得到不同结果（C1 和 C2）。 因此，事情发生的一切根源缘于我们的认知(认知是指人们对事件的想法，解释和评价等）。事物的本身并不影响人，人们只受对事物看法的影响。 听了这么多道理，好好去做才是正道。成功不必在我，而功力必不唐捐。 参考资料： 从学校到职场的转变 为什么时间管理上讲优先做的事情是最重要但不紧急的事情？By 黛西瓜 湖畔大学梁宁将情绪 ABC 理论神谕为“人的底层操作系统”，比能力强大 100 倍！By 水伯 结构性思维 By 浩翊 赠与今年的大学毕业生(1932 年 6 月 27 日) By 胡适","tags":[]},{"title":"领域驱动设计（DDD）","date":"2020-09-12T04:20:09.000Z","path":"2020/09/12/领域驱动设计（DDD）/","text":"1. 名词解释 领域：将业务根据不同范围细分，当细分到一定的程度后，不同业务会有不同范围，在这个范围内解决业务问题就是领域。 实体：就是业务对象，具有业务行为，业务逻辑和唯一 ID。实体类通常采用充血模型，包含了实体的属性和实体相关的所有业务逻辑方法，跨多个实体的领域逻辑则在领域服务中实现。 值对象：是若干个属性的集合，没有 ID，不包含业务逻辑，可以被其他实体共享，采用贫血模型。实体和值对象是微服务底层的最基础的对象，一起实现实体最基本的核心领域逻辑。&gt; 传统的数据建模是根据数据库范式设计的，每一个数据库表对应一个实体，每一个实体的属性值用单独的一列来存储，一个实体主表会对应 N 个实体从表。值对象在数据库持久化做了简化了设计，它的数据库设计大多采用非数据库范式，值对象的属性值和实体对象的属性值可以保存在不同表中。 聚合：是由业务和逻辑紧密关联的实体和值对象组合的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化。 聚合根：是实体，有实体的特点，具有全局唯一标识，是聚合的入口，聚合根与聚合根之间通过 ID 关联的方式实现聚合之间的协同。 领域事件（Domain Event）：这种事件发生后通常会导致进一步的业务操作。 2. 分层 用户接口层：面向前端提供服务适配，面向资源层提供资源适配。这一层聚集了接口适配相关的功能。 应用层：实现服务组合和编排，适应业务流程快速变化的需求。这一层聚集了应用服务和事件相关的功能。 领域层：实现领域的核心业务逻辑。这一层聚集了领域模型的聚合、聚合根、实体、值对象、领域服务和事件等领域对象，以及它们组合所形成的业务能力。 基础层：贯穿所有层，为各层提供基础资源服务。这一层聚集了各种底层资源相关的服务和能力。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://luckzp.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"快排里的Partition应用-找第K大的数字","date":"2020-09-12T04:20:04.000Z","path":"2020/09/12/快排里的Partition应用-找第K大的数字 /","text":"tags:[刷题] Partition 算法参考自：白话经典算法系列之六 快速排序 快速搞定 挖数填坑： 12345678910111213141516171819202122int partition(vector&lt;int&gt;&amp; nums, int low, int high)&#123; // 将当期的第low个元素设置为枢轴值，对数组进行划分 int x = nums[low]; int i = low; int j = high; while(i&lt;j) &#123; while(i&lt;j&amp;&amp;nums[j]&lt;=x) j--; // 将比枢轴值大的元素移动到左端 nums[i]=nums[j]; while(i&lt;j&amp;&amp;nums[i]&gt;=x) i++; // 将比枢轴值小的元素移动到右端 nums[j]=nums[i]; &#125; // 枢轴存放到的最终位置 nums[i]=x; // 返回枢轴存放到的最终位置 return i;&#125; 对算法最好的理解就是手动模拟一遍算法。 FindKthNumber123456789101112131415161718int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; int begin = 0, end = nums.size(); int target_num = 0; while (begin &lt;= end)&#123; int pos = partition(nums, begin, end); if(pos == k-1)&#123; target_num = nums[pos]; break; &#125; else if(pos &gt; k-1)&#123; end = pos; &#125; else&#123; begin = pos + 1; &#125; &#125; return target_num;&#125; 全部代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include&lt;cstdio&gt;#include&lt;vector&gt;using namespace std;int partition(vector&lt;int&gt;&amp; nums, int low, int high)&#123; int x = nums[low]; int i = low; int j = high-1; while(i&lt;j) &#123; while(i&lt;j&amp;&amp;nums[j]&lt;=x) j--; if(i&lt;j) nums[i]=nums[j]; while(i&lt;j&amp;&amp;nums[i]&gt;=x) i++; if(i&lt;j) nums[j]=nums[i]; &#125; nums[i]=x; return i;&#125;int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; int begin = 0, end = nums.size(); int target_num = 0; while (begin &lt;= end)&#123; int pos = partition(nums, begin, end); if(pos == k-1)&#123; target_num = nums[pos]; break; &#125; else if(pos &gt; k-1)&#123; end = pos; &#125; else&#123; begin = pos + 1; &#125; &#125; return target_num;&#125;int main()&#123; vector&lt;int&gt; nums=&#123;2, 1&#125;; printf(&quot;%d&quot;, findKthLargest(nums, 2)); getchar();&#125; 例题：Kth Largest Element in an Array","tags":[]},{"title":"计算机网络基础概念","date":"2020-09-12T04:19:59.000Z","path":"2020/09/12/计算机网络基础概念/","text":"1.OSI 和 TCP/IP 的体系结构，以及各层协议OSI 分层 （7 层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。TCP/IP 分层（4 层）：数据链路层、 传输层、网络层、 应用层。 分层的好处： 各层之间的接口部分规划好之后，每个层次内部的设计就能自由改动了。 设计变得相对简单，每一层只考虑自己的分配任务。 每一层的协议如下：物理层：RJ45、CLOCK、IEEE802.3 （中继器，集线器）数据链路：PPP、FR、HDLC、VLAN、MAC （网桥，交换机）网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器）传输层：TCP、UDP、SPX会话层：NFS、SQL、NETBIOS、RPC表示层：JPEG、MPEG、ASII应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS每一层的作用如下：物理层：通过媒介传输比特,确定机械及电气规范（比特 Bit）数据链路层：将比特组装成帧和点到点的传递（帧 Frame）网络层：负责数据包从源到宿的传递和网际互连（包 PackeT）传输层：提供端到端的可靠报文传递和错误恢复（段 Segment）会话层：建立、管理和终止会话（会话协议数据单元 SPDU）表示层：对数据进行翻译、加密和压缩（表示协议数据单元 PPDU）应用层：允许访问 OSI 环境的手段（应用协议数据单元 APDU） 2.TCP 的三次握手与四次分手摘自于http://www.jellythink.com/archives/705三次握手是什么？TCP 是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP 窗口大小信息。这就是面试中经常会被问到的TCP 三次握手。只是了解 TCP 三次握手的概念，对你获得一份工作是没有任何帮助的，你需要去了解 TCP 三次握手中的一些细节。先来看图说话。 多么清晰的一张图，当然了，也不是我画的，我也只是引用过来说明问题了。 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为 1，Sequence Number为 x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确 认，设置Acknowledgment Number为 x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为 1，Sequence Number为 y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为 y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成 TCP 三次握手。 完成了三次握手，客户端和服务器端就可以开始传送数据。以上就是 TCP 三次握手的总体介绍。 为了加深理解，举个例子。 A 和 B 之间建立了 TCP 连接，A 向 B 发送报文段，其中序号字段 seq=300，确认号字段 ACK =101，数据部分包含 7 个字节，那么在 B 对该报文的确认报文段中（）。 A. seq=301, ACK=101 B. seq=301, ACK=108 C.seq=101, ACK =107 D .seq=101, ACK= 307 解析： A 向 B 发送报文段，其中序号字段 seq=300，确认号字段 ACK =101。 A 对 B 说：“我已经收到你第 100 个序列号了，下个序列号要从 101 开始。我现在给你要以 300 序列号开始，给 7 个字节数据。“ B 这时应该对 A 说：”好的，我这就给你发送 101 的序列号，我这里收到了以 300 为起点，306 为终点的数据了，我现在要 307 序列号了。“ 所以 B 对该报文的确认报文段中 seq=101, ACK= 307. 选 D. 那四次分手呢？当客户端和服务器通过三次握手建立了 TCP 连接以后，当数据传送完毕，肯定是要断开 TCP 连接的啊。那对于 TCP 的断开连接，这里就有了神秘的“四次分手”。 第一次分手：主机 1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机 2 发送一个FIN报文段；此时，主机 1 进入FIN_WAIT_1状态；这表示主机 1 没有数据要发送给主机 2 了； 第二次分手：主机 2 收到了主机 1 发送的FIN报文段，向主机 1 回一个ACK报文段，Acknowledgment Number为Sequence Number加 1；主机 1 进入FIN_WAIT_2状态；主机 2 告诉主机 1，我“同意”你的关闭请求； 第三次分手：主机 2 向主机 1 发送FIN报文段，请求关闭连接，同时主机 2 进入LAST_ACK状态； 第四次分手：主机 1 收到主机 2 发送的FIN报文段，向主机 2 发送ACK报文段，然后主机 1 进入TIME_WAIT状态；主机 2 收到主机 1 的ACK报文段以后，就关闭连接；此时，主机 1 等待 2MSL 后依然没有收到回复，则证明 Server 端已正常关闭，那好，主机 1 也可以关闭连接了。 等待 2MSL 才 CLOSED 的原因是： 要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。 使已失效的连接请求报文段消失。 为什么连接的时候是三次握手，关闭的时候却是四次握手？ 因为当 Server 端收到 Client 端的 SYN 连接请求报文后，可以直接发送 SYN+ACK 报文。其中 ACK 报文是用来应答的，SYN 报文是用来同步的。但是关闭连接时，当 Server 端收到 FIN 报文时，很可能并不会立即关闭 SOCKET，所以只能先回复一个 ACK 报文，告诉 Client 端，”你发的 FIN 报文我收到了”。只有等到我 Server 端所有的报文都发送完了，我才能发送 FIN 报文，因此不能一起发送。故需要四步握手。 3.子网划分现有两个 C 类网，202.203.204.0 ，把它平均分成 4 个子网，写出每个子网的起始、终结 IP 和子网掩码。202.203.204.0 分成 4 个平均的子网，这是个 C 类的网络 ，平均分成 4 个的话，也就是每个子网有 64 台机器。2 的 2 次方=4 ，所以需要借 2 个主机位表示 网络 ，等于是 26 位的子网掩码.子网掩码: 202.203.204.192子网号 00 202.203.204.1 ~ 202.203.204.63子网号 01 202.203.204.64 ~ 202.203.204.127子网号 10 202.203.204.128 ~ 202.203.204.191子网号 11 202.203.204.192 ~ 202.203.204.254","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://luckzp.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"泛型类与泛型方法","date":"2020-09-12T04:19:54.000Z","path":"2020/09/12/泛型类与泛型方法/","text":"1 泛型类泛型类的声明和非泛型类的声明类似，除了在类名后面添加了类型参数声明部分。设计这个类的时候，在类的声明上，加上一个，表示该类支持泛型。 T 是 type 的缩写，也可以使用任何其他的合法的变量，比如 A,B,X 都可以，但是一般约定成俗使用 T，代表类型。 实例如下实例演示了我们如何定义一个泛型类: 1234567891011121314151617181920212223public class Box&lt;T&gt; &#123; private T t; public void add(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125; public static void main(String[] args) &#123; Box&lt;Integer&gt; integerBox = new Box&lt;Integer&gt;(); Box&lt;String&gt; stringBox = new Box&lt;String&gt;(); integerBox.add(new Integer(10)); stringBox.add(new String(&quot;菜鸟教程&quot;)); System.out.printf(&quot;整型值为 :%d\\n\\n&quot;, integerBox.get()); System.out.printf(&quot;字符串为 :%s\\n&quot;, stringBox.get()); &#125;&#125; 2 泛型方法 所有泛型方法声明都有一个类型参数声明部分（由尖括号分隔），该类型参数声明部分在方法返回类型之前（在下面例子中的&lt; T &gt; ）。 12345678public static &lt;T&gt; T jsonToEntity (String json, Class&lt;T&gt; targertClass) &#123; if(!StringUtils.isEmpty(json)) &#123; T entity = JSON.parseObject(json, targertClass); return entity; &#125; return null;&#125; 3 T 与?区别大家可能会有疑问，那无边界通配符？与泛型变量 T 有什么区别呢？答案是：他们俩没有任何联系！！！！！泛型变量 T 不能在代码用于创建变量，只能在类，接口，函数中声明以后，才能使用。 而无边界通配符？则只能用于填充泛型变量 T，表示通配任何类型！！！！再重复一遍：？只能用于填充泛型变量 T。它是用来填充 T 的！！！！只是填充方式的一种！！！ 1234&#x2F;&#x2F;无边界通配符填充Box&lt;?&gt; box;&#x2F;&#x2F;其它类型填充Box&lt;String&gt; stringBox; 类型参数“”主要用于第一种，声明泛型类或泛型方法。无界通配符“&lt;?&gt;”主要用于第二种，使用泛型类或泛型方法。","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"单体到微服务","date":"2020-09-12T04:19:49.000Z","path":"2020/09/12/单体到微服务/","text":"最近读了《大型网站系统与 Java 中间件实践》，书 14 年的，老了点。后面的感觉没啥可看的，就讲讲学到的。从单体项目转向分布式的项目，所要解决的问题和 Spring Cloud 组件相对应。 1.服务之间网络通信问题在原来的单体项目中，只需要调不同的方法就能完成业务不同的操作。到了分布式中，根据业务的不同会拆分成不同的服务，A 服务依赖于 B 服务。这时候涉及 A 服务与 B 服务的网络通信问题（如下图）。 在 Spring Cloud 是靠着 Feign,Ribbon, Eureka 注册中心得以实现。 Eureka：各个服务启动时，Eureka Client 都会将服务注册到 Eureka Server，并且 Eureka Client 还可以反过来从 Eureka Server 拉取注册表，从而知道其他服务在哪里。Eureka Serve 里面有一个注册表，保存了各服务所在的机器和端口号。 Ribbon：首先 Ribbon 会从 Eureka Client 里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。Ribbon 使用负载均衡算法（默认使用的最经典的Round Robin 轮询算法）从一个服务的多台机器中选择一台。 Feign：基于 Feign 的动态代理机制，根据注解和选择的机器，拼接请求 URL 地址，发起请求。 2. 某个服务挂了怎么办在单体项目中，要是挂了，整个项目就用不了。在分布式架构中，A 服务挂了但是不影响 B 服务的运行，用户依然可以进行 B 服务的操作。在 SpringCloud 中通过Hystrix实现。 Hystrix：发起请求是通过 Hystrix 的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。 当 A 服务挂了，A 服务会被熔断。请求 A 服务会立即返回。Hystrix 流程图 参考https://juejin.im/post/5d56204a5188252bd409b5cb","tags":[{"name":"分布式","slug":"分布式","permalink":"https://luckzp.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"操作系统","date":"2020-09-12T04:19:39.000Z","path":"2020/09/12/操作系统/","text":"1.线程线程是程序执行流的最小单位。一个标准的线程由线程 ID，当当前指令(PC)，寄存器集合和堆栈(stack)组成。另外，线程是进程中的一个实体，是系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的资源。 线程共享的进程环境包括：进程代码段、进程的公有数据（如全局变量，利用这些共享的数据，线程很容易的实现相互之间的通信）、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户 ID 与进程组 ID。 2.进程的通信方式有哪些？ 管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://luckzp.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"财务分析和决策","date":"2020-09-12T04:19:34.000Z","path":"2020/09/12/财务分析和决策/","text":"一个企业所做的事情就是 3 件事情：经营，投资，融资。资产负债表，利润表，现金流量表这 3 大报表反映了一个企业的情况。 现金流量表这个维度，这个维度它描述了这个企业的未来是不是能够持续经营。资产负债表和利润表，它们共同构成另一个维度，假设这个企业能够继续生存下去，那么它的状况会是什么样子的？ 1.资产负债表(Balance Sheet) 资产与费用的区别 Difference between Asset &amp; Cost花一笔钱出去，换来一个未来有用额东西，这就是资产，如果钱花完后什么都没有留下，那就是费用 净资产=股东权益=资产-负债每股净资产 = 净资产/股本数市值 = 每股价格*股本数市净率（PB） = 市值/净资产 = 每股价格/每股净资产 2.利润表 (Income Statement) 每股利润 = 净利润/股本数。市盈率（PE）= 每股价格/每股利润。利润表两大作用 现在公司赚多少钱 形成对公司未来赢利预期的基础 3.现金流量表(Cash Flow Statement) 现金流量表作用告诉我们现金增减变化如何发生的？（是经营活动？是融资活动？是投资活动？） 4.总资产报酬率","tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://luckzp.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TCP的拥塞控制机制","date":"2020-09-12T04:19:24.000Z","path":"2020/09/12/TCP的拥塞控制机制/","text":"拥塞控制（congestion control)是 TCP 协议的一项重要功能，TCP 的拥塞控制机制是从端到端的角度，推测网络是否发生拥塞，如果推断网络发生拥塞，则立即将数据发送速率降下来，以便缓解网络拥塞。TCP 的拥塞控制算法包括了慢启动（slow start）、拥塞避免（congestion avoidance）、快速重传（fast retransmit）和快速恢复（fast recovery）四部分。 慢启动（slow start）和拥塞避免（congestion avoidance）控制过程： -[1]. TCP 连接初始化，将拥塞窗口 cwind 设置为 1 个报文段，即 cwind=1； -[2]. 执行慢开始算法，cwind 按指数规律增长，直到 cwind == ssthresh 时，开始执行拥塞避免算法，cwind 按线性规律增长； -[3]. 当网络发生拥塞，把 ssthresh 值更新为拥塞前 ssthresh 值的一半，cwind 重新设置为 1，再按照 [2] 执行。 例题： 设某 TCP 的拥塞窗口的慢启动门限值初始为 8(单位为报文段，且最大报文段长度 1KB)，当拥塞窗口上升到 12 时，网络会发生超时。按照以上给出的条件，第 12 次传输网拥塞窗口的大小为( )。 A. 5 B. 6 C. 7 D. 8 解析：B 在慢启动和拥塞避免算法中，拥塞窗口初始值为 1，窗口大小开始按指数增长。当拥塞窗口大于慢启动门限后，停止使用慢启动算法，改用拥塞避免算法。此时，慢启动的门限值初始为 8，当拥塞窗口增大到 8 时改用拥塞避免算法，窗口大小按线性增长，毎次增长 1 个报文段。当增加到 12 时，出现超时，重新设置门限值为 6(12 的一半)，拥塞窗口再重新设为 1，执行慢启动算法，到门限值为 6 时执行拥塞避免算法。按照上面的算法，拥塞窗口的变化为 1、2、4、8、9、10、11、12、1、2、4、6、7、8、9…，从该序列可以看出，第 12 次传输时拥塞窗口大小为 6。 注意：在以上的序列中，6 被加粗，原因是很多考生直接从 4 增加到 8，导致误选 D 选项。原因是拥塞窗口的大小是与门限值有关的，在慢开始算法中不能直接变化为大千门限值，所以 4 只能最多增加到 6，之后再执行拥塞避免算法。","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://luckzp.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"OKR学习","date":"2020-09-12T04:19:19.000Z","path":"2020/09/12/OKR学习/","text":"title: OKR 学习 date: 2020-02-03 22:07:56tags: 个人提升 1. OKR 与心理学在人性角度上讲，承诺的事情就要去努力做到。深层次来看，OKR 便恰恰体现了这样一种“承诺”精神，这也是社会心理学中提到的“承诺和一致原理”，即人们通常会将自己的承诺与行动保持一致。此外，当我们看到许多人在同时做某件事情时，自己也会跟着去效仿，这就是社会心理学中所提到的“从众心理”。 2. OKR 制定注意事项O： 方向明确：目标不能太抽象，也不能含混不清，要让每个人都能看得懂。 目标对齐：下级要对齐上级的目标，即向上对齐，平级还要相互对齐，即水平对齐。 时间限制：目标需要有时间边界，不能遥遥无期，而且时间边界要恰到好处。 O 尽可能要以动词形式开头。例如：打造……、建设……、实现……。 O 最好能附上一句目标描述。建议为 O 增加一句话描述，就“为何我要写这个目 标？”这一问题，来向大家讲解。 KR： 有挑战性：关键结果要有挑战性，拒绝平庸，拒绝不切实际，要做到“跳一跳，就能够 得着”。 容易度量：无法度量的关键结果是没有任何意义的，宁可抛弃。 不是任务：关键结果需要对目标产生直接影响，它不是日常任务，也不是行动计划。 O 和 KR 之间是“一对多”的关系。既然 OKR 需要考虑时间限制，最多不要超过 3 个，否则就容易导致精力有限，不够聚焦。每个 O 所包含的 KR 也无需太多，最多也不要超过 3 个。 3. OKR 与 KPI 区别 KPI 是是由上级领导制定，自己需要去执行，中间难免会有“讨价还价”的过程；OKR 是根据上级领导的 KR 来制定自己的 OKR，能激发其主观能动性。 KPI 是工业时代下的产物，它提倡用结果来说话，进而减少过程中的管理成本。适合于重复 性机械劳动比如拧螺丝钉。OKR 是互联网时代下的产物，更适合用探索型工作，没有现成的指令和方法可以遵循。 OKR 与 KPI 结合使用：KPI 中包括的绩效指标一定是只看结果，而不看过程的，只要结果达到了就行，而 OKR 需要更多地关心过程，从结果中判断目标的具体达成情况。 4. OKR 的对齐 不建议将上级 KR 变成下级 O，这样会降低 OKR 系统的稳定性。比如，如果上级 KR 变化，就会导致下级 O 变化，从而导致下级 KR 变化。 OKR 所提倡的“对齐”指的是在 O 上做出支撑，下级需要支撑上级的 O，平级之间也要相互支撑，然而 KR 只是为了支撑自己的 O。 5. OKR 使用不当OKR 是自驱力较强的人自我成长的利器，一定要了解 OKR 的这一特性：OKR 落地不需要让人在后面不断催促，然后才能出结果的。否则，就必然会适得其反。在这过程中，如果你用了 OKR，反而让大家产生了更大的压力，那就起反作用了，因此也失去了 OKR 原本的“功效”。 6. OKR 评分 1.0 分：不可能做到，但实际做到了。 0.7 分：希望能做到，实际也做到了。 0.3 分：肯定能做到，实际也做到了。 0 分：肯定能做到，但实际没做到。 OKR 评分不是跟别人比，而是跟自己的过去比，自己有没有进步？有没有超越过去的自己？","tags":[]},{"title":"NIO初识","date":"2020-09-12T04:19:14.000Z","path":"2020/09/12/NIO初识/","text":"tags:[Java] 1.NIO 概念同步非阻塞 IO(socket 主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的 I/O 操作是同步阻塞的)，通常用于网络服务器进行多路复用 IO。Redis，Nginx, Tomcat8.X 采用这种方式，RabbitMQ 采用类似这种思想。 以 nginx 为例，ngnix 会有很多请求进来， epoll 会把他们都监视起来，然后像拨开关一样，谁有数据就拨向谁，然后调用相应的代码处理。 2.epollepoll 可以理解为 event poll，不同于忙轮询和无差别轮询，epoll 之会把哪个流发生了怎样的 I/O 事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了 O(k)，k 为产生 I/O 事件的流的个数)。 3.selector新事件(读就绪、写就绪、有新连接到来)到来的时候，会在 selector 上注册标记位，标示可读、可写或者有连接到来。**Selector.select()**是阻塞的，通过操作系统的通知（epoll）这个函数是阻塞的。可以在一个 while(true)里面调用这个函数而不用担心 CPU 空转。","tags":[]},{"title":"MySQL中的B+树","date":"2020-09-12T04:19:09.000Z","path":"2020/09/12/MySQL中的B+树/","text":"tags:[MySQL] 索引mysql 中的索引底层使用的是 B+树，索引存储在硬盘中，而非内存中。考虑性能，要减少磁盘 IO 次数。构建 M 叉树，M 越大，树的高度越小，磁盘 IO 变少了。举例：如果 m 叉树中的 m 是 100，那对一亿个数据构建索引，树的高度也只是 3（层数是 4），最多只要 3 次磁盘 IO 就能获取到数据（第一层节点存在内存里）。磁盘 IO 变少了，查找数据的效率也就提高了。 那 m 叉树中的 m 是不是越大越好呢？到底多大才最合适呢？ 不管是内存中的数据，还是磁盘中的数据，操作系统都是按页（一页大小通常是 4KB，这个值可以通过 getconfig PAGE_SIZE 命令查看）来读取的，一次会读一页的数据。如果要读取的数据量超过一页的大小，就会触发多次 IO 操作。所以，我们在选择 m 大小的时候，要尽量让每个节点的大小等于一个页的大小。读取一个节点，只需要一次磁盘 IO 操作。","tags":[]},{"title":"MySQL实战-学习笔记(2)","date":"2020-09-12T04:19:04.000Z","path":"2020/09/12/MySQL实战-学习笔记(2)/","text":"tags:[MySQL] 7 行锁功过：怎么减少行锁对性能的影响？两阶段锁协议 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。在一个事务中，把最可能发生锁冲突的 SQL 语句放在最后，减少锁行的时间。 8 事务到底是隔离的还是不隔离的？可重复读 事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。 一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。当前读 VS 快照读 当事务隔离级别是可重复读时 快照读： 读取的是事务开启前的数据，比如 select。```sqlselect * from table … 1234567891011- 当前读：总是读取已经提交完成的最新版本。特殊的读操作，插入 &#x2F; 更新 &#x2F; 删除操作，属于当前读，处理的都是当前的数据，需要加锁。&#96;&#96;&#96;sqlselect * from table where ? lock in share mode; S 锁，Gap 锁select * from table where ? for update; X 锁，Gap 锁insert; X 锁，Gap 锁update ; X 锁，Gap 锁delete; X 锁，Gap 锁 读操作通常加共享锁（Share locks，S 锁，又叫读锁），写操作加排它锁（Exclusive locks，X 锁，又叫写锁）；加了共享锁的记录，其他事务也可以读，但不能写；加了排它锁的记录，其他事务既不能读，也不能写。 9 普通索引和唯一索引，应该怎么选择？Update 语句普通索引会用到 change buffer 减少磁盘 IO，先把数据记录到 change buffer,然后当查询的时候触发 merge 将数据同步到磁盘上，从而达到比唯一索引快的目的。但是针对于更新完后，立即访问对应的数据页，会增加了 change buffer 维护代价。 13 为什么表数据删掉一半，表文件大小不变？delete 删除数据，但是实际上数据页并没有被删除，而是留着被复用。如果要减小文件大小通过 optimize table t 。通过如下程序实验，先通过存储过程 idata 新增数据然后查询表文件大小，后 delete 删除后发现表文件大小没变，最后通过 optimize table t 来减少了表文件大小。 12345678begindeclare i int;set i=1000;while(i&lt;=10000)doinsert into user values(i, i);set i=i+1;end while;end 123456select concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;M&#x27;) from tables;CALL idata();select concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;M&#x27;) from tables;DELETE FROM `user` where user_id &gt; 6;select concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;M&#x27;) from tables;optimize table `user`; 15 临时表建表语法是 1create temporary table … 临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。 16 Join 使用注意 小标表作为驱动表。 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。","tags":[]},{"title":"MySQL实战-学习笔记(1)","date":"2020-09-12T04:18:59.000Z","path":"2020/09/12/MySQL实战-学习笔记(1)/","text":"tags:[MySQL] 1 一条 SQL 查询语句是如何执行的？创建数据库连接，SQL 经过分析器分析语义，优化器选择合适的索引，选择最佳的执行方案，最后执行器执行。如果是更新语句，先是查找到这行，然后才执行更新操作。 2 日志系统：一条 SQL 更新语句是如何执行的？Mysql 中的 Binlog 有 2 种模式，statement 模式记录的是 sql 语句，row 格式会记录的行的内容，记录 2 条，更新前和更新后。Mysql 默认执行引擎 Innodb 的 redo log 记录数据页有什么改动。relog 采用 2 阶段提交保证和 binlog 的一致性。日志系统使用场景当误操作后或多搭建一个读库的时候，现在常见的做法就是全量备份和加上 Binlog 来实现的。如果 relog 和 binlog 不一致，会导致恢复的数据库数据不一致或主从数据库不一致的情况发生。日志系统参数配置innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。日志系统命令全量备份命令 1mysqldump -u[username] -p[password] [database] [table] &gt; backup.sql 恢复备份命令 1mysql -u[username] -p[password] [database] &lt; backup.sql 当然也可以用 Mysql 可视化工具进行备份。 3 事务隔离：为什么你改了我还看不见？在一个事务里，实际上每条记录在更新的时候都会同时记录一条回滚日志操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。大事务的弊端 大事务会导致记录大量的回滚操作，在这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 大事务还占用锁资源，提高死锁概率，长时间占用连接，也可能拖垮整个库。 大事务的排查在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 同时也可以排查 Lock wait timeout exceeded; try restarting transaction 异常，找到相应的线程并 kill thread id。 锁等待超时。是当前事务在等待其它事务释放锁资源造成的。可以找出锁资源竞争的表和语句。 4 深入浅出索引回表普通索引查询方式，则需要先搜索 普通索引树，得到一个主键索引的值，再到主键 索引树搜索一次。这个过程称为回表。普通索引树的叶子节点是主键值,主键索引树的叶子节点是数据。所以，普通索引树比主键索引树小很多。回表是一行行地查数据，因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。覆盖索引 1select ID from T where k between 3 and 5 这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。不再需要回表查整行记录，减少语句的执行时间。联合索引（a,b）也可以达到覆盖索引的要求。假如现在有个查询是 1select b from T where a = x 这样也不用回表了。建组合索引的时候，区分度最高的在最左边。","tags":[]},{"title":"Join工作原理","date":"2020-09-12T04:18:54.000Z","path":"2020/09/12/Join工作原理/","text":"tags:[MySQL] Join 工作原理1.Index Nested-Loop Join可以使用被驱动表的索引走的是 Index Nested-Loop Join。 执行流程是这样的： 在这个流程里： 对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行； 而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行； 所以，整个执行流程，总扫描行数是 200。 2.Block Nested-Loop Join不能使用被驱动表的索引,流程是这样的: 在这个流程里： 由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。 join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。","tags":[]},{"title":"ELK初识","date":"2020-09-12T04:18:49.000Z","path":"2020/09/12/ELK初识/","text":"ELK 是Elasticsearch，Logstash，Kibana 三个组件组合起来的缩写。 Elasticsearch 是搜索引擎，Logstash 是收集数据输出到 elasticsearch 中。Kibana 是Elasticsearch 数据的可视化，类比于 navicat 是 Mysql 数据的可视化。 1. ElasticSearch 概念画一个对比图来类比传统关系型数据库： 关系型数据库 -&gt; Databases(库) -&gt; Tables(表) -&gt; Rows(行) -&gt; Columns(列)。 Elasticsearch -&gt; Indeces(索引) -&gt; Types(类型) -&gt; Documents(文档) -&gt; Fields(属性)。 索引 一个索引(index)就像是传统关系数据库中的数据库，它是相关文档存储的地方。 文档 就是一个对象 Json 串。 分片（shards） 索引可能存储大量可能超过单个节点的硬件限制的数据，需要将索引细分，细分后的部分是分片。 副本（Replicasedit） 副本，是对分片的复制。 倒排索引 就是通过文档中的字段反查到文档的 id。 ES 的 JSON 文档中的每个字段，都有自己的倒排索引。 组成：单词字典（单词到倒排列表的关系）和倒排列表（记录了单词对应文档的结合）。 2. 搭建 ELK 环境读取数据库 下载版本相同的 elasticsearch，logstash，kibana。 logstash 安装 logstash-jdbc-input 插件。 配置 logstash.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960input &#123; #beats &#123; # port =&gt; 5044 #&#125; jdbc &#123; # 数据库 数据库名称为elk，表名为book_table jdbc_connection_string =&gt; &quot;jdbc:mysql://127.0.0.1:3306/tmall_springboot?characterEncoding=UTF-8&quot; # 用户名密码 jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;123456&quot; # jar包的位置 jdbc_driver_library =&gt; &quot;E:\\ELK\\logstash-7.5.2\\mysql-connector-java-5.1.30.jar&quot; # mysql的Driver jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;100&quot; #statement_filepath =&gt; &quot;E:\\logstash-7.3.0\\config\\viewlogs.sql&quot; statement =&gt; &quot;select * from category where id &gt; :sql_last_value&quot; schedule =&gt; &quot;* * * * *&quot; #是否记录上次执行结果, 如果为真,将会把上次执行到的 tracking_column 字段的值记录下来,保存到 last_run_metadata_path 指定的文件中 record_last_run =&gt; true #是否需要记录某个column 的值,如果 record_last_run 为真,可以自定义我们需要 track 的 column 名称，此时该参数就要为 true. 否则默认 track 的是 timestamp 的值. use_column_value =&gt; true #如果 use_column_value 为真,需配置此参数. track 的数据库 column 名,该 column 必须是递增的.比如：ID. tracking_column =&gt; id #指定文件,来记录上次执行到的 tracking_column 字段的值 #比如上次数据库有 10000 条记录,查询完后该文件中就会有数字 10000 这样的记录,下次执行 SQL 查询可以从 10001 条处开始. #我们只需要在 SQL 语句中 WHERE MY_ID &gt; :last_sql_value 即可. 其中 :last_sql_value 取得就是该文件中的值(10000). #last_run_metadata_path =&gt; &quot;E:\\ELK\\logstash-7.5.2\\viewlogs&quot; #是否清除 last_run_metadata_path 的记录,如果为真那么每次都相当于从头开始查询所有的数据库记录 clean_run =&gt; false #是否将 column 名称转小写 #lowercase_column_names =&gt; false &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;http://localhost:9200&quot;] #按分钟 #index =&gt; &quot;mysql-%&#123;+YYYY.MM.dd.HH.mm&#125;&quot; #按小时 index =&gt; &quot;logstashmysql&quot; #index =&gt; &quot;wdnmd&quot; #index =&gt; &quot;%&#123;[servicename]&#125;&quot; #index =&gt; &quot;logstash-%&#123;[fields][document_type]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; #index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; #user =&gt; &quot;elastic&quot; #password =&gt; &quot;changeme&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 在 logstash 当前目录下启动 logstash 1bin/logstash -f logstash.conf 3. 用 sql 语句查询 elasticsearch安装的 elasticsearch 是 7.5.2 版本，可以用 sql 语句查询 elasticsearch。 1234POST &#x2F;_sql?format&#x3D;txt&#123; &quot;query&quot;: &quot;SELECT order_id FROM goodslist WHERE goods_list like &#39;%抽纸%&#39; group by order_id&quot;&#125; SQL 转 DSL 1234POST &#x2F;_sql&#x2F;translate?format&#x3D;txt&#123; &quot;query&quot;: &quot;SELECT * FROM mobile_index WHERE mobile like &#39;%760714206%&#39;&quot;&#125;","tags":[{"name":"运维","slug":"运维","permalink":"https://luckzp.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"SpringBoot启动过程和SpringMVC的工作原理","date":"2020-09-12T04:18:44.000Z","path":"2020/09/12/SpringBoot启动过程和SpringMVC的工作原理/","text":"SpringBoot 启动过程 执行@SpringBootApplication。 初始化 SpringApplication 对象，获取当前目录 META-INF/spring.factories 信息，设置加载资源（ApplicationContextInitializer，ApplicationListener）。 执行 SpringApplication 对象的 run 方法。 初始化 ConfigurableEnvironment，执行 listeners.environmentPrepared 方法。 创建并初始化 ApplicationContext。 refresh ApplicationContext, 将带有注解@Bean,@Component,@PropertySource,@ComponentScan,@Import @ImportResource 加入到 ioc 容器中，其中自动装配通过@Import({AutoConfigurationImportSelector.class})实现，通过 org.springframework.boot.autoconfigure.EnableAutoConfiguration 工厂类装配。 Spring Bean 生命周期 SpringMVC 工作原理在 SpringBoot 启动过程中，创建了 Tomcat 和 DispatcherServlet。 当有请求时，会被 DispatcherServlet#doDispatch 处理，处理流程图如下： 实践源码","tags":[{"name":"Spring","slug":"Spring","permalink":"https://luckzp.github.io/tags/Spring/"}]},{"title":"01背包和完全背包问题","date":"2020-09-12T04:18:35.000Z","path":"2020/09/12/01背包和完全背包问题/","text":"layout: posttitle: “01 背包和完全背包问题”date: 2018-01-07 21:27comments: truereward: truetags: 校招 01 背包问题描述容量为 m 的背包和 n 个物品，每个物品都有各自的体积 v 和价值 val，从这 n 个物品中选择多个物品放在包里而物品体积总数不超过包的容量 m 时，能够得到的最大价值是多少？ 一般同学们会考录到用贪心的算法通过求最大的性价比来填满背包，这样会有什么样的不妥之处了？ 贪心与背包问题的不同 首先说一下贪心是每一步都是最优的决策，就是每次方我都会放进去解决问题的目前最好的结果。 贪心虽然会带来每一次最优但是不一定是整体最优。(比如说 C 的性价比最高，但是放了 C 就不能放别的了，总价值就不如放 A 和 B 的多了) 背包可以从宏观上整体得到一个最优的结果。 01 背包问题解析 问题的特点是：每种物品一件，可以选择放 1 或不放 0。 用子问题定义状态：即 f[i][v]表示前 i 件物品恰放入一个容量为 v 的背包可以获得的最大价值。则其状态转移方程便是：f[i][v] = max(f[i-1][v-p[i]] + w[i], f[i-1][v]) 如果在这里第 i 件物品放的话就表明它是由第 i-1 的状态传递过来的并且加上新的价值 w[i]，如果不放就表明这里是保持第 i-1 的状态没有增加新的价值。 代码如下： 1234567891011for(i=0; i&lt;=n; i++) dp[i][0] = 0; for(i=0; i&lt;=v; i++) dp[0][i] = 0; for(i=1; i&lt;=n; i++)&#123; for(j=0; j&lt;=v; j++)&#123; dp[i][j] = dp[i-1][j]; if(j&gt;=p[i]) dp[i][j] = max(dp[i-1][j], dp[i-1][j-p[i]]+w[i]); &#125; &#125; printf(&quot;%d\\n&quot;, dp[n][v]); &#125; 手工模拟代码： 解释这个表： 有三个物品 就用 (3,4), (4,5), (5,6) 表示（对应表左边） 用 C(i)(j) 表示表 C ，j 为横， i 为纵 从 C(1)(1)开始，此时你只有一个物品 (3,4) 和一个 容量为 j = 1 的背包。 因为 3 &gt; 1 所以不能装入，所以此时背包内物品价值为 C(1)(1)= 0 同理 C(1)(2)时，背包 j = 2，3 &gt; 2，C(1)(2)= 0 C(1)(3)时 背包大小为 3 刚好能装下这个大小为 3 的物品 所以 C(1)(3) = 4 之后因为只有物品 (3,4) 可选 所以包里价值都是 4 ………… C(3)(10) 的时候三种物品都可选，最佳组合是 (4,5) 和 (5,6)，所以 C(3)(10) = 5 + 6 = 11. 01 背包代码优化原式子(二维的): f[i][v] = max&#123;f[i-1][v-p[i]] + w[i], f[i-1][v]&#125; 现在要改成一维的(空间优化): f[v] = max&#123;f[v-p[i]] + w[i], f[v]&#125; 注意上面的状态转移方程两边的是 2 个状态(左边的是这一状态 右边的是上一状态（二维的通过 i 可以看出来）) f[i][v]是由f[i-1][v-c[i]]推出来的,现在要把二维的改成一维的,即要推 f[v],要保证 f[v]由 f[v-c[i]]推出来，如果 v 是顺序递增的,则相当于f[i][v]变得是由f[i][v-c[i]]推出来的,而不是由原来的f[i-1][v-c[i]]推的. 具体分析见：01 背包问题 总结关于为什么 01 背包优化成 1 维数组后,内层循环是逆序的? f[i][v]只与f[i-1][v]和f[i-1][v-C[i]]有关，即只和 i-1 时刻状态有关，所以我们只需要用一维数组 f[]来保存 i-1 时的状态 f[]。 假设 i-1 时刻的 f[]为{a0，a1，a2，…，av}，难么 i 时刻的 f[]中第 v 个应该为 max(av,av-C[i]+W[i])即 max(f[v],f[v-C[i]]+W[i])，这就需要我们遍历 V 时逆序遍历，这样才能保证求 i 时刻 f[v]时 f[v-C[i]]是 i-1 时刻的值。如果正序遍历则当求 f[v]时,其前面的 f[0],f[1]，…，f[v-1]都已经改变过，里面存的都不是 i-1 时刻的值，这样求 f[v]时利用 f[v-C[i]]必定是错的值。最后 f[V]即为最大价值. 12345678910for(i=0; i&lt;=v; i++)&#123; dp[i] = 0; &#125; for(i=1; i&lt;=n; i++)&#123; for(j=v; j&gt;=0; j--)&#123; if(j&gt;=p[i]) dp[j] = max_num(dp[j], dp[j-p[i]]+w[i]); &#125; &#125; printf(&quot;%d\\n&quot;, dp[v]); &#125; 完全背包问题描述容量为 m 的背包和 n 种物品，每个物品都有各自的体积 v 和价值 val，每种物品都有无限件可用，将哪些物品装入背包物品体积总数不超过包的容量 m 时，能够得到的最大价值是多少？ 完全背包问题解析这个问题非常类似于 01 背包问题，所不同的是每种物品有无限件。也就是从每种物品的角度考虑，与它相关的策略已并非取或不取两种，而是有取 0 件、取 1 件、取 2 件……等很多种。如果仍然按照解 01 背包时的思路，令f[i][v]表示前 i 种物品恰放入一个容量为 v 的背包的最大权值。仍然可以按照每种物品不同的策略写出状态转移方程： f[i][v]=max&#123;f[i-1][v-k*c[i]]+k*w[i]|0&lt;=k*c[i]&lt;=v&#125; 同样可以转换成一维数组来表示： 伪代码如下： 12345678910for (int i=1; i&lt;=n; i++) for (int j=1; j&lt;=v; j++) &#123; if (p[i]&lt;=j) &#123; f[j]=max(f[j],f[j-p[i]]+w[i]); &#125; &#125;cout&lt;&lt;f[v]&lt;&lt;endl;//输出最优解 顺序！想必大家看出了和 01 背包的区别，这里的内循环是顺序的，而 01 背包是逆序的。 现在关键的是考虑：为何完全背包可以这么写？ 在次我们先来回忆下，01 背包逆序的原因？是为了是 max 中的两项是前一状态值，这就对了。 那么这里，我们顺序写，这里的 max 中的两项当然就是当前状态的值了，为何？ 因为每种背包都是无限的。当我们把 i 从 1 到 N 循环时，f[v]表示容量为 v 在前 i 种背包时所得的价值，这里我们要添加的不是前一个背包，而是当前背包。所以我们要考虑的当然是当前状态。","tags":[]},{"title":"高度自适应 文档流 浮动流","date":"2020-09-12T04:17:37.000Z","path":"2020/09/12/高度自适应 文档流 浮动流/","text":"普通流就是正常的文档流，在 HTML 里面的写法就是从上到下，从左到右的排版布局。 例：很显然这是最普通的文档流，从左到右，一个挨一个按照顺序 01 先，02 其次，03 最后排列。 一旦给其中的某个 DIV 进行 FLOAT 属性或者 absolute 定位（不包括 static/relative，这两个依然保持正常的文档流），则它完全脱离文档流，不占空间。例：为了能更好辨认，我分别给 01 绿色，02 灰色，03 黄色。然后再给 01 左浮动。结果，01 脱离了文档流，完全不占空间，所以 02 顺势顶替了 01 原来的位置，结果 02 被 01 盖住了。 同理，absolute 定位跟 float 一样，脱离了文档流，不再占原来文档流的空间了。再举一个大家在日常经常遇到的问题来印证—高度自适应 反复想一想，高度自适应的原理其实就是这个： 1234567&lt;div id&#x3D;”a”&gt;&lt;div id&#x3D;”b”&gt;这是b&lt;&#x2F;div&gt;&lt;div id&#x3D;”c”&gt;这是c&lt;&#x2F;div&gt;&lt;&#x2F;div&gt; 这个结构是 a 包住 b 和 c，颜色不变，a 的高度为自动，b 的高度为 100，C 的高度为 500。b 和 c 都为左浮动。 很明显 a 没有被撑开了。原因是它们浮动了就不再占空间了。既然没有空间可占，那就等于容器里没有东西，所以不撑开。 知道这个问题后，我就没有将 b 设置为浮动，高度就自适应到 b 的高度了。","tags":[{"name":"前端","slug":"前端","permalink":"https://luckzp.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"ajax学习","date":"2020-09-12T04:17:32.000Z","path":"2020/09/12/ajax学习/","text":"Ajax 是一种异步请求数据的 web 开发技术，对于改善用户的体验和页面性能很有帮助。简单地说，在不需要重新刷新页面的情况下，Ajax 通过异步请求加载后台数据，并在网页上呈现出来。常见运用场景有表单验证是否登入成功。需求：点击登陆按钮时，提交账号和密码给后端，异步刷新显示返回的数据。Demo 代码： 123456789101112131415161718192021222324252627282930313233343536373839&lt;script&gt; $(function() &#123; $(&quot;#submitBtn&quot;).click(function() &#123; if(0 == $(&quot;#username&quot;).val().length || 0==$(&quot;#password&quot;).val().length)&#123; $(&quot;#errorMessage&quot;).text(&quot;输入账号密码为空&quot;); $(&quot;#loginErrorMessageDiv&quot;).css(&quot;visibility&quot;,&quot;visible&quot;); return false; &#125;else&#123; var username = $(&quot;#username&quot;).val(), password = $(&quot;#password&quot;).val(); $.ajax(&#123; type: &quot;POST&quot;, data: &#123;username: username, password: password&#125;, //传输的数据 dataType:&quot;json&quot;, //传输的数据类型 url: &quot;/loginsuccess&quot;, //提交目的地址 success: function (data) &#123; //返回的数据为data对象，该对象有msg和code两个属性 console.log(data); if (data.code == 1) &#123; $(&quot;#errorMessage&quot;).text(data.msg); $(&quot;#loginErrorMessageDiv&quot;).css(&quot;visibility&quot;,&quot;visible&quot;); return false; &#125; else &#123; window.location.href=data.msg; return true; &#125; &#125;, error: function (data) &#123; alert(&quot;认证失败&quot;); &#125; &#125;); &#125; &#125;); $(&quot;input&quot;).keyup(function()&#123; $(&quot;#loginErrorMessageDiv&quot;).css(&quot;visibility&quot;,&quot;hidden&quot;); &#125;); &#125;);&lt;/script&gt; 效果图：","tags":[{"name":"前端","slug":"前端","permalink":"https://luckzp.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"万历王朝的兴衰史","date":"2020-09-12T04:16:44.000Z","path":"2020/09/12/万历王朝的兴衰史/","text":"最近读了有关历史有关的书籍，发现万历王朝的兴衰，与当朝的皇帝和辅臣有关系。我想基于此，可以去凭借后人写的史书去分析一下这个王朝的兴衰。然后以此为鉴，避免掉入前人的坑。 万历皇帝是从小在张居正的陪伴下成长起来的。由于年龄太小，每次临朝时还需要在衣袖里抽出一张别人事先为他书写的纸片，边看边答复各个官员的呈奏请示。在那时候他看来，张先生似乎永远就是智慧的象征，他的意见就代表了自己的旨意。 万历十年，在张居正的努力下,国库日见充实，外部倭寇也已绝迹，成就了万历王朝欣欣向荣的十年。但也正是因为张居正位高权重，凡有弹劾张居正的官员都遭到了惩处。他的儿子在科举中分别中了状元，榜眼，引起了普遍的质疑，但他毫不在意。 1582 年，张居正长逝，他死时，北京的粮仓装满了够吃 9 年的粮食，府库里也堆满了银子。但也就在张居正仅去世半年后，反张派开始揭发事实，制造舆论，使他的形象逐渐变得虚伪和毒辣。这一切都让年轻的皇帝感到他对张居正的信任是一种错误。2 年后，张居正被抄家了。 万历二十年，宁夏副总兵哱拜叛变，为了对付叛乱，皇帝从北方辽东，山西等地调集军队进行镇压。这次军事行动花费了一百八十万两白银。同一年，明政府发兵抗击日本丰臣秀吉政权入侵朝鲜，花费七百八十万两。8 年后，苗疆土司杨应龙叛乱，政府再次出兵镇压。史书记载：这三场战役为“万历三大征”，巩固了中华疆土，维护了明朝在东亚的主导地位。但国家财政的赤字已经达到了一百万两，而且年年赤字。这时，皇帝开始利用张居正留下的税务系统进行加税，勉强渡过难关。但随后在后金王朝的连绵进攻下，多次加税筹集军饷调遣军队，最终导致了民间经济的奔溃，出现大饥荒，带来了造反潮。 古语有云：知史以明鉴，查古以至今。从万历角度来看，作为皇帝，一定要有自己的主见，对事情要自己的清晰看法，不能过于听信他人的看法。做事情去权衡各方的利益，去协调各方。 从张居正角度来看，张居正一方面通过改革税法让政府收入大幅增加，成就明朝最富裕的十年，另一方面其在位权力过于庞大，排除异己，死后遭到抄家。我从中可以知道两点，第一点，权力要受到监管。第二点，很多事和人都是由黑与白交织成的灰色。从不同的方面看出来的颜色也不同。 从国家角度来说，其实打仗就是伤敌一千，自损八百的事。就算打赢了胜仗，宣告了国家的主权地位，但国家的经费也会大大消耗。当国家财政无法支撑军饷时，政府就会想办法在民间获取经济来源，导致老百姓的日子跟着受苦。 虽说明朝距离我们现在已有五六百年时间了，但历史事件背后的逻辑依然在当今出现。我想读史，给我最大的感受就是运用发现了现在的一些事情怎么和历史上的事情这么相似，这时去套用历史的逻辑去看现在的事情，会有新的发现。","tags":[]},{"title":"区块链初认识","date":"2020-09-12T04:16:39.000Z","path":"2020/09/12/区块链初认识/","text":"读自：区块链技术指南 我现在的理解来说区块链就是去中心化的分布式记账系统，只可能添加记录，发生过的记录都不可篡改。 比特币是基于区块链技术的一种应用，其中都会涉及到密码学，博弈论，记账技术，分布式系统。 关于博弈论，书中有个有趣的例子。","tags":[]},{"title":"How to see past your own perspective and find truth","date":"2020-09-12T04:15:05.000Z","path":"2020/09/12/How to see past your own perspective and find truth/","text":"You can’t strive to inhabit that space if you don’t already accept that you live in the same reality. To accept that, we’ve got to believe in truth, we’ve got to encourage more active ways of knowing. And we’ve got to have the humility to realize that we’re not the measure of all things. https://www.ted.com/talks/michael_patrick_lynch_how_to_see_past_your_own_perspective_and_find_truth","tags":[]},{"title":"Does money make you mean","date":"2020-09-12T04:15:00.000Z","path":"2020/09/12/Does money make you mean/","text":"layout: posttitle: “Does money make you mean?”comments: truedate: 2019-5-20 11:15:07tags: TED Does money make you mean?what are we facing?American dream is an idea in which we all have an equal opportunity to succeed and prosper, as long as we apply ourselves and work hard. And a piece of that means that sometimes, you need to put your own interests above the interests and well-being of other people around you. But what we’re finding is that the wealthier you are, the more likely you are to pursue a vision of personal success, of achievement and accomplishment, to the detriment of others around you.We’re at unprecedented levels of economic inequality. What that means is that wealth is not only becoming increasingly concentrated in the hands of a select group of individuals, but the American dream is becoming increasingly unattainable for an increasing majority of us. And if it’s the case, as we’ve been finding, that the wealthier you are, the more entitled you feel to that wealth, and the more likely you are to prioritize your own interests above the interests of other people, and be willing to do things to serve that self-interest. what do we do?we’ve been finding in our own laboratory research that small psychological interventions, small changes to people’s values, small nudges in certain directions,can restore levels of egalitarianism and empathy. For instance, reminding people of the benefits of cooperation or the advantages of community, cause wealthier individuals to be just as egalitarian as poor people. https://www.ted.com/talks/paul_piff_does_money_make_you_mean","tags":[]},{"title":"MongoDB设计表方式","date":"2020-09-11T06:53:01.000Z","path":"2020/09/11/MongoDB设计表方式/","text":"内嵌模式1-N 的情况，通过数组内嵌模式来形成一个文档。N-N 的情况，以前在关系性数据库中通过建立中间表来转成一对多的情况，用了 MongoDB 不用映射表，通过冗余的方式实现 N-N。 引用模式内嵌后文档大小超过 16MB数组长度太大（数万以上）内嵌文档或数组元素会频繁修改","tags":[]},{"title":"CPU上下文切换过程","date":"2020-09-11T06:51:03.000Z","path":"2020/09/11/CPU上下文切换过程/","text":"CPU 上下文切换过程：当一个用户态的程序运行到一半，要访问一个核心资源，例如访问网卡发一个网络包，就需 要暂停当前的运行，调用系统调用，接下来就轮到内核中的代码运行了。首先，内核将从系统调用传过来的包，在网卡上排队，轮到的时候就发送。发送完了，系统 调用就结束了，返回用户态，让暂停运行的程序接着运行。这个暂停怎么实现呢？其实就是把程序运行到一半的情况保存下来。例如，我们知道，内存 是用来保存程序运行时候的中间结果的，现在要暂时停下来，这些中间结果不能丢，因为再 次运行的时候，还要基于这些中间结果接着来。另外就是，当前运行到代码的哪一行了，当 前的栈在哪里，这些都是在寄存器里面的。所以，暂停的那一刻，要把当时 CPU 的寄存器的值全部暂存到一个地方，这个地方可以放 在进程管理系统很容易获取的地方。在后面讨论进程管理数据结构的时候，我们还会详细 讲。当系统调用完毕，返回的时候，再从这个地方将寄存器的值恢复回去，就能接着运行了。","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://luckzp.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"双指针运用","date":"2020-09-10T14:40:24.000Z","path":"2020/09/10/双指针运用/","text":"双指针逼近法：双指针相向夹逼，从两头开始向中间移动。leetcode-15.3SumGiven an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Note: The solution set must not contain duplicate triplets. 1234567For example, given array S &#x3D; [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 题意：在给定的一个数组中找到三个之数为 0 的组合。Note：1.用暴力的方法，时间复杂度会达到 O(n),用双指针逼近法将时间复杂度降到 O(n2)。 2.三个数的组合中有相同的组合，要考虑到去除重复的。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; sum; //save three elements whose sum = 0; sort(nums.begin(), nums.end()); int temp_a=-1;int temp_b=-1; int temp_c = -1; for (int i = 0; i &lt; nums.size(); i++) &#123; if (i!=0 &amp;&amp;nums[i] == nums[i-1])//avoid duplicate nums[i] continue; int aa = nums[i]; int l = i+1; int r = nums.size()-1;//two pointer while(l&lt;r) &#123; int temp = aa+nums[l]+nums[r]; if(temp == 0) &#123; //avoid duplicate triplets if(temp_a != aa || temp_b != nums[l] || temp_c != nums[r]) &#123; temp_a=aa; temp_b=nums[l]; temp_c=nums[r]; vector&lt;int&gt;temp_sum; temp_sum.push_back(temp_a); temp_sum.push_back(temp_b); temp_sum.push_back(temp_c); sum.push_back(temp_sum); temp_sum.clear(); &#125; l++;//move pointer r--; &#125; else if(temp &lt; 0)//move pointer l++; else r--; &#125; &#125; return sum; &#125;&#125;; leetcode-11.Container With Most WaterGiven n non-negative integers a1, a2, …, an, where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. Note:每个点之间的横坐标是等间隔的。要求出最大的容器，是由“短板”高来决定的和宽，所以这里采用双指针逼近法一开始将两个指针分别指向首和尾，然后逐渐向中间逼近求出最大容器。 123456789101112131415161718192021222324class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int l = 0; int r = height.size()-1;//two pointer int ans = 0 ; while(l &lt; r) &#123; int temp = (r-l)*min(height[l],height[r]);//calculating formula if(temp &gt; ans) ans = temp; if(height[l] == height[r]) if(height[r-1] &gt; height[l+1]) r--;//pointer move else l++; else if(height[l] &lt; height[r]) l++; else r--; &#125; return ans; &#125;&#125;; 快速排序做完这两个题，使我快排的认识比以前认识更深了，因为快排中也用到类似的双指针逼近法。 123456789101112131415161718192021void quick_sort(int a[], int l, int r)&#123; if (l &lt; r)&#123; int x = a[l];//chose a pivot int i = l; int j = r;//two pointer while (i &lt; j) &#123; while (i &lt; j &amp;&amp; x &lt;= a[j])//find a number which is less than pivot j--; if (i&lt;j)//find a number a[i] = a[j]; while (i &lt; j &amp;&amp; x &gt; a[i]) i++; if (i&lt;j) a[j] = a[i]; &#125; a[i] = x; quick_sort(a, l, i - 1); quick_sort(a, i + 1, r); &#125;&#125; 白话经典算法系列之六 快速排序 快速搞定","tags":[{"name":"算法","slug":"算法","permalink":"https://luckzp.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"链表","date":"2020-09-10T14:40:18.000Z","path":"2020/09/10/链表/","text":"链表的题目，思考起来不难，考察的是实现代码的能力，思路是否清晰明了，代码是否简洁。 https://leetcode.com/problems/reverse-linked-list/```javapublic static ListNode reverseList(ListNode head) {// 在遍历列表时，将当前节点的 next 指针改为指向前一个元素。// 由于节点没有引用其上一个节点，因此必须事先存储其前一个元素。// 在更改引用之前，还需要另一个指针来存储下一个节点。ListNode cur = head;ListNode prev = null;while (cur != null){ListNode nextTemp = cur.next;cur.next = prev;prev = cur;cur = nextTemp;}return prev;} 123456789101112132. [https:&#x2F;&#x2F;leetcode.com&#x2F;problems&#x2F;swap-nodes-in-pairs&#x2F;](https:&#x2F;&#x2F;leetcode.com&#x2F;problems&#x2F;swap-nodes-in-pairs&#x2F;)理解递归&#96;&#96;&#96;javapublic static ListNode swapPairs(ListNode head) &#123; if (head &#x3D;&#x3D; null || head.next &#x3D;&#x3D; null) &#123; return head; &#125; ListNode next &#x3D; head.next; head.next &#x3D; swapPairs(next.next); next.next &#x3D; head; return next; &#125; 将两个有序顺序表合并成一个新的有序顺序表，并由函数返回结果顺序表。 1234567891011121314151617bool Merge(SeqList A, SeqList B, SeqList &amp;C)&#123; if(A.length + B.length &gt; C.maxSize) return false; int i = 0, j = 0, k = 0; while(i &lt; A.length &amp;&amp; j &lt; B.length)&#123; if(A.data[i] &lt;= B.data[j]) C.data[k++] = A.data[i++]; else C.data[k++] = B.data[j++]; &#125; while(i &lt; A.length) C.data[k++] = A.data[i++]; while(j &lt; B.length) C.data[k++] = A.data[j++]; C.length = k+1; return true;&#125; 设 L 为带头结点的单链表，编写算法实现从尾到头反向输出每个节点的值。 key: 想到调用栈这点很重要。 123456void R_Print(LinkList L)&#123; if(L-&gt;next != NULL)&#123; R_Print(L-&gt;next); &#125; printf(L-&gt;data);&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://luckzp.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"C++笔面试题目","date":"2020-09-10T14:40:09.000Z","path":"2020/09/10/C++笔面试题目/","text":"layout: posttitle: “C 笔面试题目”date: 2017-09-18 16:42comments: truereward: truetags: C 1.函数指针a.获取函数地址 12process(think);//passes address of think() to process()thought(think);//passes return value of think to thought() b.声明函数指针 12345double pam(int);//prototypedouble (*pf)(int);//pf points to a function that takes //one int argument and that //return type doublepf = pam;//pf now points to the pam() function 为提供正确的运算符优先级，必须在声明中使用括号将* pf 括起。括号的优先级比*运算符高。 12double (*pf)(int);//pf points to a function that returns doubledouble *pf(int); //pf() a function that return a pointer-to-double 注意，pam()的参数列表和返回类型必须与 pf 相同。如果不相同，编译器将拒绝这种赋值： 12345double ned(double);int ted(int);double (*pf)(int);pf = ned;//invalid -- mismatched signaturepf = ted;//invalid -- mismatched return type c.使用指针来调用函数 12345678double pam(int);//prototypedouble (*pf)(int);//pf points to a function that takes //one int argument and that //return type doublepf = pam;//pf now points to the pam() functiondouble x = pam(4);//call pam() using the function namedouble y = (*pf)(5);//call pam() using the pointer pfdouble y = pf(5);//also call pam() using the pointer pf 2.虚函数工作原理：编译器处理虚函数的方法是：给每个对象添加一个隐藏成员。隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表(virtual function table，vtbl)。虚函数表中存储了为类对象进行声明的虚函数地址。 3.结构体内存对齐1.什么是内存对齐假设我们同时声明两个变量：char a;short b;用&amp;（取地址符号）观察变量 a，b 的地址的话，我们会发现（以 16 位 CPU 为例）：如果 a 的地址是 0x0000，那么 b 的地址将会是 0x0002 或者是 0x0004。那么就出现这样一个问题：0x0001 这个地址没有被使用，那它干什么去了？ 答案就是它确实没被使用。 因为 CPU 每次都是从以 2 字节（16 位 CPU）或是 4 字节（32 位 CPU）的整数倍的内存地址中读进数据的。如果变量 b 的地址是 0x0001 的话，那么 CPU 就需要先从 0x0000 中读取一个 short，取它的高 8 位放入 b 的低 8 位，然后再从 0x0002 中读取下一个 short，取它的低 8 位放入 b 的高 8 位中，这样的话，为了获得 b 的值，CPU 需要进行了两次读操作。但是如果 b 的地址为 0x0002，那么 CPU 只需一次读操作就可以获得 b 的值了。所以编译器为了优化代码，往往会根据变量的大小，将其指定到合适的位置，即称为内存对齐（对变量 b 做内存对齐，a、b 之间的内存被浪费，a 并未多占内存）。 2.结构体内存对齐规则（请记住三条内存规则(在没有#pragam pack 宏的情况下）结构体所占用的内存与其成员在结构体中的声明顺序有关，其成员的内存对齐规则如下： （1）每个成员分别按自己的对齐字节数和 PPB（指定的对齐字节数，32 位机默认为 4）两个字节数最小的那个对齐，这样可以最小化长度。如在 32bit 的机器上，int 的大小为 4，因此 int 存储的位置都是 4 的整数倍的位置开始存储。 （2）复杂类型(如结构)的默认对齐方式是它最长的成员的对齐方式，这样在成员是复杂类型时，结构体数组的时候，可以最小化长度。 （3）结构体对齐后的长度必须是成员中最大的对齐参数（PPB）的整数倍，这样在处理数组时可以保证每一项都边界对齐。 （4）结构体作为数据成员的对齐规则：在一个 struct 中包含另一个 struct，内部 struct 应该以它的最大数据成员大小的整数倍开始存储。如 struct A 中包含 struct B, struct B 中包含数据成员 char, int, double，则 struct B 应该以 sizeof(double)=8 的整数倍为起始地址。 3.实例演示：12345678910111213struct A&#123;char a; //内存位置: [0]double b; // 内存位置: [8]...[15]int c; // 内存位置: [16]...[19] ---- 规则1&#125;; // 内存大小：sizeof(A) = (1+7) + 8 + (4+4) = 24, 补齐[20]...[23] ---- 规则3struct B&#123;int a, // 内存位置: [0]...[3]A b, // 内存位置: [8]...[31] ---- 规则2char c, // 内存位置: [32]&#125;; // 内存大小：sizeof(B) = (4+4) + 24 + (1+7) = 40, 补齐[33]...[39] *注释：(1+7)表示该数据成员大小为 1，补齐 7 位；(4+4)同理。","tags":[]},{"title":"线程池","date":"2020-09-10T03:00:57.000Z","path":"2020/09/10/线程池/","text":"1. 线程池的原理 不会初始化 corePoolSize 个线程，有任务来了才创建工作线程； 当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列中； 当工作队列满了后扩容线程池，一直到线程个数达到 maximumPoolSize 为止； 如果队列已满且达到了最大线程后还有任务进来，按照拒绝策略处理； 当线程数大于核心线程数时，线程等待 keepAliveTime 后还是没有任务需要处理的话，收缩线程到核心线程数。 2. 创建线程池使用 ThreadPoolExecutor 创建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;import org.springframework.core.task.TaskRejectedException;/** * 通用线程池任务处理执行器 * */public class HandleTaskExecutor &#123; /** * 核心线程大小 */ private static int CORE_POOL_SIZE = 8; /** * 线程池最大线程数 */ private static int MAX_POOL_SIZE = 64; /** * 额外线程空状态生存时间 */ private static int KEEP_ALIVE_TIME = 30 * 1000; /** * 队列大小 */ private static int MAX_QUEUE_SIZE = 30000; private HandleTaskExecutor()&#123;&#125; private static class TmcHandleTaskExecutorHolder&#123; static HandleTaskExecutor me = new HandleTaskExecutor(); &#125; /** * 拿到执行器实例 * @return */ public static HandleTaskExecutor me() &#123; return TmcHandleTaskExecutorHolder.me; &#125; /** * 线程池 */ private static ThreadPoolExecutor THREAD_POOL = new ThreadPoolExecutor(CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.MICROSECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(MAX_QUEUE_SIZE), new ThreadFactory() &#123; private final AtomicInteger index = new AtomicInteger(); @Override public Thread newThread(Runnable r) &#123; String threadName = &quot;任务处理线程[HandleTaskExecutor]-&quot; + (null != r ? r.getClass().getSimpleName() : &quot;&quot;) + &quot;#&quot; + index.getAndIncrement(); return new Thread(r, threadName); &#125; &#125;, new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 线程池过载 抛出异常 String info = &quot;&quot;; if (r instanceof AbstractHandleTask) &#123; AbstractHandleTask task = (AbstractHandleTask) r; info = task.rejected(); &#125; throw new TaskRejectedException(String.format(&quot;线程池过载，任务被拒绝。%s&quot;, info)); &#125; &#125;); /** * 添加任务 */ public void execute(AbstractHandleTask handleTask) throws Exception &#123; THREAD_POOL.execute(handleTask); &#125; /** * 线程池基本状态信息 * @return */ public String status() &#123; StringBuffer info = new StringBuffer(&quot;HandleTaskExecutor&quot;); info.append(&quot;, getQueue().size() : &quot;).append(THREAD_POOL.getQueue().size()); info.append(&quot;, remainingCapacity : &quot;).append(THREAD_POOL.getQueue().remainingCapacity()); info.append(&quot;, MAX_QUEUE_SIZE : &quot;).append(HandleTaskExecutor.MAX_QUEUE_SIZE); info.append(&quot;, getPoolSize : &quot;).append(THREAD_POOL.getPoolSize()); info.append(&quot;, getActiveCount : &quot;).append(THREAD_POOL.getActiveCount()); info.append(&quot;, getCorePoolSize : &quot;).append(THREAD_POOL.getCorePoolSize()); info.append(&quot;, getMaximumPoolSize : &quot;).append(THREAD_POOL.getMaximumPoolSize()); info.append(&quot;, getLargestPoolSize : &quot;).append(THREAD_POOL.getLargestPoolSize()); return info.toString(); &#125;&#125; 3. 复用线程池线程池必须复用而不是按需创建，但是不推荐一味混用一个线程池。对于选择是否混用线程池，至少对于频+快的任务和少+慢的任务应该分开，还是要根据实际任务的性质来选择。","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"线程安全","date":"2020-09-10T02:59:50.000Z","path":"2020/09/10/线程安全/","text":"多线程保证数据安全性保证数据线程安全的思路基本有以下三种，这三种中又分别有不同的做法： 线程封闭技术，让数据只能被单个线程所见。如 Threadlocal 使用原子类如 AtomicInteger 其底层就是 volatile 和 CAS 共同作用的结果。首先使用了 volatile 保证了内存可见性。然后使用了 CAS（compare-and-swap）算法 保证了原子性。 其中 CAS 算法的原理就是里面包含三个值：内存值 A 预估值 V 更新值 B 当且仅当 V == A 时，V = B; 否则，不会执行任何操作。 同步技术，正确的发布并维护共享数据。如 synchronized 锁，即线程 A 获取到锁后，线程 B 阻塞直到线程 A 释放锁，线程 B 才能获取到同一个锁 。 创建线程或线程池时指定有意义的名称，方便出错时排查。 重新考虑全局变量。 编写可重复执行的函数，可以借助锁来实现。","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"equals和hashcode","date":"2020-09-10T02:58:55.000Z","path":"2020/09/10/equals和hashcode/","text":"equals 方法注重 两个对象在逻辑上是否相等。 1） 只要重写 equals ，就必须重写 hashCode 。2） 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须重写这两个方法。3） 如果自定义对象做为 Map 的键，那么必须重写 hashCode 和 equals 。说明： String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象作为 key 来使用。 1234567891011121314151617181920212223242526272829public class VideoDto &#123; private String id; private String description; private String path; private String extensionName; private Long size; private Long videoDuration; private Map&lt;String, String&gt; extend; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; VideoDto that = (VideoDto) o; return Objects.equal(path, that.path); &#125; @Override public int hashCode() &#123; return Objects.hashCode(path); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"MQ消息一致性","date":"2020-09-10T02:57:47.000Z","path":"2020/09/10/MQ消息一致性/","text":"4. MQ 消息事务一致性主要是让消息持久化。 上游应用，执行业务并发送指令给可靠消息服务并保留消息副本。 可靠消息服务和 MQ 消息组件，协调上下游消息的传递，并确保上下游数据的一致性。 下游应用，监听 MQ 的消息并执行自身业务并保留消息副本。","tags":[]},{"title":"分布式锁","date":"2020-09-10T02:56:56.000Z","path":"2020/09/10/分布式锁/","text":"1.CAP 与分布式锁 C：Consistency（一致性） A：Availability（可用性） P：Partition tolerance（分区容错性） 在基于 Redis 实现的 AP 架构的分布式锁模型中，向 Redis 节点 1 写入数据后，会立即返回结果，之后在 Redis 中会以异步的方式来同步数据。在基于 Zookeeper 实现的 CP 架构的分布式模型中，向节点 1 写入数据后，会等待数据的同步结果，当数据在大多数 Zookeeper 节点间同步成功后，才会返回结果数据。 2. redis 分布式锁的实现setnx 命令为例子，由于 Redis 的单线程命令处理机制，如果有多个客户端同时执行 setnx key value，根据 setnx 的特性只有一个客户端能设置成功，setnx 可以作为分布式锁的一种实现方案。 1234567891011121314151617181920212223242526public class RedisTool &#123; private static final String LOCK_SUCCESS = &quot;OK&quot;; private static final String SET_IF_NOT_EXIST = &quot;NX&quot;; private static final String SET_WITH_EXPIRE_TIME = &quot;PX&quot;; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125;","tags":[{"name":"分布式","slug":"分布式","permalink":"https://luckzp.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"剖析HashMap","date":"2020-09-10T02:23:27.000Z","path":"2020/09/10/剖析HashMap/","text":"HashMap 集合的底层原理。 转自：https://juejin.im/post/5aa5d8d26fb9a028d2079264#heading-23 2. HashMap 为什么线程不安全 Put 的时候会导致数据会覆盖 删除键值对 addEntry 中当加入新的键值对后键值对总数量超过门限值的时候会调用一个 resize 操作 比如有两个线程 A 和 B，首先 A 希望插入一个 key-value 对到 HashMap 中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程 A 的时间片用完了，而此时线程 B 被调度得以执行，和线程 A 一样执行，只不过线程 B 成功将记录插到了桶里面，假设线程 A 插入的记录计算出来的桶索引和线程 B 要插入的记录计算出来的桶索引是一样的，那么当线程 B 成功插入之后，线程 A 再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程 B 插入的记录，这样线程 B 插入的记录就凭空消失了。","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"锁","date":"2020-09-10T02:22:29.000Z","path":"2020/09/10/锁/","text":"1.锁的分类 2. JMM 与内存可见性synchronized: 通过高级字节码 monitor_enter 和 monitor_exit 实现的。 volatile: 强制变量的赋值会强制刷新回主内存，强制变量的读取从主内存中重新加载。 3. synchronized 锁什么时候升级 4. lock 可以用来做什么锁 ReentrantLock ReentrantReadWriteLock.ReadLock ReentrantReadWriteLock.WriteLock StampedLock.ReadLockView StampedLock.WriteLockView","tags":[{"name":"Java","slug":"Java","permalink":"https://luckzp.github.io/tags/Java/"}]},{"title":"类加载机制","date":"2020-09-10T02:17:23.000Z","path":"2020/09/10/类加载机制/","text":"代码如何在 JVM 运行的 12345public class A &#123; public static void main(String[] args) &#123; B b = new B() &#125;&#125; 类加载器加载过程校验-&gt;准备-&gt;解析-&gt;初始化 类加载器加载类方式:双亲委派模型： 1.防止类重复加载，避免用户自己编写的类动态替换 Java 的一些核心类，比如 String。 2.防止对 JAVA 核心 API 的篡改。 JVM 触发初始化的情况 当虚拟机启动时，初始化用户指定的主类。 当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类。 当遇到调用静态方法的指令时，初始化该静态方法所在的类。 当遇到访问静态字段额指令时，初始化该静态字段所在的类。 子类的初始化会触发父类的初始化。 如果一个接口定义了 default 方法，那么直接实现或间接实现该接口的类的初始化，会触发该接口的初始化。 使用反射 API 对某个类进行反射调用时，初始化这个类。 当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。 在 Hotspot 虚拟机中，对象的内存布局。对象在内存布局分为 3 块区域：对象头，实例数据和对齐填充。对象头包含 2 部分，第一部分存储对象运行的数据如哈希码，GC 分代年龄，锁状态标志，线程持有的锁，偏向线程 ID，偏向时间戳，又称为Mark Word。另一部分是类型指针。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://luckzp.github.io/tags/JVM/"}]},{"title":"垃圾回收算法","date":"2020-09-10T01:53:10.000Z","path":"2020/09/10/垃圾回收算法/","text":"两种判断对象是否死亡的方法1. 引用计数法它的做法是为每个对象添加一个引用计数器，用来统计指向该对象的引用个数。一旦某个对象的引用计数器为 0，则说明该对象已经死亡，便可以被回收了。 2. GC Roots 可达性分析法目前 Java 虚拟机的主流垃圾回收器采取的是可达性分析算法。这个算法的实质在于将一系列 GC Roots 作为初始的存活对象合集（live set），然后从该合集出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中，这个过程我们也称之为标记（mark）。最终，未被探索到的对象便是死亡的，是可以回收的。 哪些可以当做 GC Roots 对象可以作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表） 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象； 总结就是，方法运行时，方法中引用的对象；类的静态变量引用的对象；类中常量引用的对象；Native 方法中引用的对象。 垃圾回收的三种方式1. 标记清除算法（Mark-Sweep）即把死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表（free list）之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。缺点很明显，会造成内存碎片。JVM 内部是要求内存连续的，所以就会出现总的空闲内存还比较充足但是无法分配对象的情况。** 2. 压缩（Mark-Compact）即把存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销。 3.复制（copying）即把内存区域分为两等分，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针指向的内存区域中，并且交换 from 指针和 to 指针的内容。复制这种回收方式同样能够解决内存碎片化的问题，但是它的缺点也极其明显，即堆空间的使用效率极其低下。 JVM 所采用的方法分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。 新生代：复制算法(ParNew 采用的策略)当 Eden 区域和 From 区域都内存不够的时候触发 MinorGC,MinorGC 采用复制算法。因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少。 Eden, From -&gt; To 清空 Eden, From To 和 From 互换 当老年代空间不够用时，触发 FullGC。 老年代：压缩算法（CMS 采用的策略）老年代因为每次只回收少量对象，因而采用 Mark-Compact 算法。因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存. CMS 垃圾回收流程 初步标记 并发表记 重新标记 并发清理","tags":[{"name":"JVM","slug":"JVM","permalink":"https://luckzp.github.io/tags/JVM/"}]},{"title":"二分查找容易出错的3个地方","date":"2020-08-28T07:15:15.000Z","path":"2020/08/28/二分查找容易出错的3个地方/","text":"1.循环退出条件注意是 low&lt;=high，而不是 low&lt;high。 2.mid 的取值实际上，mid=(low+high)/2 这种写法是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 low+((high-low)&gt;&gt;1)。因为相比除法运算来说，计算机处理位运算要快得多。 3.low 和 high 的更新low=mid+1，high=mid-1。注意这里的 +1 和 -1，如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致一直循环不退出。 123456789101112131415161718192021222324252627package com.leetcode;public class BinarySearch &#123; public static void main(String[] args) &#123; Integer [] a = &#123;1,2,3,4,5,6,7,9,10&#125;; System.out.println(binarySearch(a, 10)); &#125; private static int binarySearch(Integer[] a, int value) &#123; int low = 0; int high = a.length-1; while (low &lt;= high)&#123; int mid = low + ((high-low) &gt;&gt; 1); if (a[mid] == value)&#123; return mid; &#125; else if (a[mid] &lt; value)&#123; low = mid + 1; &#125; else &#123; high = mid - 1; &#125; &#125; return -1; &#125;&#125; **","tags":[{"name":"算法","slug":"算法","permalink":"https://luckzp.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"动态代理","date":"2020-08-28T07:15:10.000Z","path":"2020/08/28/动态代理/","text":"JAVA 中的动态代理：通过动态的创建一个新类，实现在运行时对类进行修改（如想知道某个类运行的时长）。 使用 JDK 和 Cglib 实现动态代理。 Spring 如何选择两种代理模式的？ 1、如果目标对象实现了接口，则默认采用 JDK 动态代理。 2、如果目标对象没有实现接口，则使用 Cglib 代理。 我们可以通过 DeBug 看到生成的代理类后缀不同来区别。 123456789101112131415161718192021222324252627282930313233package com.example.rabbitmqtest.demo.dynamicproxy;import java.lang.reflect.Proxy;public class DynamicMain &#123; public static void main(String[] args) &#123; System.out.println(&quot;=======JDK=======&quot;); Sell sell = new Vendor(); //创建中介类实例 DynamicProxy inter = new DynamicProxy(sell); //加上这句将会产生一个$Proxy0.class文件，这个文件即为动态生成的代理类文件 //System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;,&quot;true&quot;); //获取代理类实例sell Sell jdkProxy = (Sell)(Proxy.newProxyInstance(Sell.class.getClassLoader(), sell.getClass().getInterfaces(), inter)); System.out.println(jdkProxy.getClass()); //通过代理类对象调用代理类方法，实际上会转到invoke方法调用 jdkProxy.sell(); System.out.println(&quot;=======Cglib=======&quot;); //代理对象 Sell proxy = (Sell) new CglibProxy(new Vendor()).getProxyInstance(); System.out.println(proxy.getClass()); //执行代理对象方法 proxy.sell(); &#125;&#125; 12345678package com.example.rabbitmqtest.demo.dynamicproxy;/** * 委托类和代理类都实现了Sell接口 */public interface Sell &#123; void sell();&#125; 12345678910package com.example.rabbitmqtest.demo.dynamicproxy;/** * 生产厂家 */public class Vendor implements Sell &#123; public void sell() &#123; System.out.println(&quot;In sell method&quot;); &#125;&#125; 12345678910111213141516171819202122package com.example.rabbitmqtest.demo.dynamicproxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class DynamicProxy implements InvocationHandler&#123; //obj为委托类对象; private Object obj; public DynamicProxy(Object obj) &#123; this.obj = obj; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;jdk before&quot;); Object result = method.invoke(obj, args); System.out.println(&quot;jdk after&quot;); return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738package com.example.rabbitmqtest.demo.dynamicproxy;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CglibProxy implements MethodInterceptor &#123; private Object target; public CglibProxy(Object target) &#123; this.target = target; &#125; //为目标对象生成代理对象 public Object getProxyInstance() &#123; //工具类 Enhancer en = new Enhancer(); //设置父类 en.setSuperclass(target.getClass()); //设置回调函数 en.setCallback(this); //创建子类对象代理 return en.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;cglib before&quot;); Object result = method.invoke(target, args); System.out.println(&quot;cglib after&quot;); return result; &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://luckzp.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","date":"2020-08-28T07:15:05.000Z","path":"2020/08/28/单例模式/","text":"面试考察点 对单例模式的理解。 对静态构造函数，类初始化。 对多线程编程的理解。 静态内部类12345678910111213141516public class Singleton &#123; private Singleton()&#123; &#125; private static class LazyLoader&#123; final static Singleton INSTANCE = new Singleton(); &#125; // 只有当调用Singleton.getInstance时，程序才会访问LazyHolder.INSTANCE,才会触发对LazyLoader的初始化 // 然后新建一个实例 // 由于类初始化是线程安全的，并且仅被执行一次，可以确保多线程情况只有一个实例。 public static Singleton getInstance()&#123; return LazyLoader.INSTANCE; &#125;&#125; 只有当调用 Singleton.getInstance 时，程序才会访问 LazyHolder.INSTANCE,才会触发对 LazyLoader 的初始化(当遇到访问静态字段的指令时，初始化该静态字段所在的类)，由于类初始化是通过加锁的，并且仅被执行一次，可以确保多线程情况只有一个实例。 双重检查12345678910111213141516171819202122232425262728public class Singleton &#123; // instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 // 1.给 instance 分配内存 // 2.调用 Singleton 的构造函数来初始化成员变量 // 3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） // 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的， // 最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了， // 这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后报错。 private volatile static Singleton singleton; private Singleton()&#123; &#125; public static Singleton getSingleton()&#123; if (singleton == null)&#123; // 通过在synchronized的外面增加一层判断，就可以在对象一经创建以后，不再进入synchronized同步块。 // 这种方案不仅减小了锁的粒度，保证了线程安全，性能方面也得到了大幅提升。 synchronized (Singleton.class)&#123; if (singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://luckzp.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"IOC与AOP","date":"2020-08-28T07:15:00.000Z","path":"2020/08/28/IOC与AOP/","text":"在面试中，经常会问，说说你对 spring IOC 和 AOP 的理解，问题很宽泛，似乎不知道从何说起。回答思路： 先用通俗易懂的话解释下何为 IOC 和 AOP。 各自的实现原理。 自己的项目中如何使用。 IOC一.定义IOC 是反转控制 (Inversion Of Control)的缩写，就像控制权从本来在自己手里，交给了 Spring。Spring IOC 的作用 不必自己创建对象了（不必 new 出来了） 面向接口编程 许多应用都是通过彼此间的相互合作来实现业务逻辑的，如类 A 要调用类 B 的方法，以前我们都是在类 A 中，通过自身 new 一个类 B，然后在调用类 B 的方法，这样对象间的耦合度高了，现在我们把 new 类 B 的事情交给 spring 来做，在我们调用的时候，容器会为我们实例化。 二.依赖注入（DI）资源定位，即定义 bean 的 xml（也可以使用@Bean）——-》载入——–》IOC 容器注册，注册 beanDefinition。IOC 容器的初始化过程，一般不包含 bean 的依赖注入的实现，在 spring IOC 设计中，bean 的注册和依赖注入是两个过程，，依赖注入一般发生在应用第一次索取 bean 的时候，但是也可以在 xm 中配置，在容器初始化的时候，这个 bean 就完成了初始化。Spring 使用：单独使用 Bean 容器（Bean 管理）。Bean 容器初始化基础：依赖两个包 org.springframework.beans 中的 BeanFactory 提供配置结构和基本功能，加载并初始化 Bean org.springframework.context 中的 ApplicationContext 保存了 Bean 对象并在 Spring 中被广泛使用 Spring 注入是指在启动 Spring 容器加载 bean 配置的时候，完成对变量的赋值行为。 AOP面向切面，所有业务都要处理的业务，如打印日志，登录拦截。要记录所有 update*方法的执行时间时间，操作人等等信息，记录到日志， 通过 spring 的 AOP 技术，就可以在不修改 update*的代码的情况下完成该需求。 spring 用代理类包裹切面，把他们织入到 Spring 管理的 bean 中。也就是说代理类伪装成目标类，它会截取对目标类中方法的调用，让调用者对目标类的调用都先变成调用伪装类，伪装类中就先执行了切面，再把调用转发给真正的目标 bean。 前一种实现 InvocationHandler 的 invoke 方法，spring 会使用 JDK 的 java.lang.reflect.Proxy 类，它允许 Spring 动态生成一个新类来实现必要的接口，织入通知，并且把对这些接口的任何调用都转发到目标类。 后一种父子模式，spring 使用 CGLIB 库生成目标类的一个子类，在创建这个子类的时候，spring 织入通知，并且把对这个子类的调用委托到目标类。 Spring AOP 会动态选择使用 JDK 动态代理、CGLIB 来生成 AOP 代理，如果目标类实现了接口，Spring AOP 则无需 CGLIB 的支持，直接使用 JDK 提供的 Proxy 和 InvocationHandler 来生成 AOP 代理即可。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://luckzp.github.io/tags/Spring/"}]},{"title":"SpringBoot中直接new对象为NULL值","date":"2020-08-28T07:14:55.000Z","path":"2020/08/28/SpringBoot中直接new对象为NULL值/","text":"SpringBoot 中直接 new 对象为 NULL 值在 springBoot 中如果直接 new 一个对象出来，那么在此对象使用了@Autowired 注解都会为 NULL 值。为了解决这个问题，我们就要了解@Autowired 的源码实现，@Autowired 注解的实现是通过后置处理器 AutowiredAnnotationBeanPostProcessor 类的 postProcessPropertyValues()方法实现的，通过找到对应@Autowired 的字段，最后通过反射注入。查找元信息和注入依赖查找和反射注入","tags":[{"name":"Spring","slug":"Spring","permalink":"https://luckzp.github.io/tags/Spring/"}]},{"title":"Maven理解","date":"2020-08-28T07:14:50.000Z","path":"2020/08/28/Maven理解/","text":"Maven 的用处 1.maven 会自动帮我们引入适用的版本 Jar 包。 2.maven 完成自动化构建（清理 → 编译 → 编译 → 部署）。 Maven 项目结构 有一个 pom.xml 用于维护当前项目都用了哪些 jar 包。 源代码都放在 src/main/java 下面。 测试代码都放在 src/test/java 下面。 配置文件都放在 src/main/resources 下面。","tags":[{"name":"运维","slug":"运维","permalink":"https://luckzp.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"JVM内存分区","date":"2020-08-27T15:35:00.000Z","path":"2020/08/27/JVM内存分区/","text":"#### 线程私有： 虚拟机栈：线程在执行方法的时候会创建一个栈帧，栈帧包含：局部变量表，操作数栈，动态链接（与其他方法相链接），方法出口等信息。 本地方法栈：与栈类型，不同点是执行 native 方法。 程序计数器：保存当前字节码的位置 线程共享： 堆：由垃圾回收器管理。 -Xms: 堆的最小值 -Xmx: 堆的最大值 新生代：Eden:From:To = 8:1:1 方法区：用以存储加载类的信息，常量，静态变量。JDK8 以前，方法区是在堆永久代中，JDK8 及以后取消了永久代，方法区挪到直接内存 MetaSpace 中。 永久代： jdk1.7 及以前： -XX:PermSize -XX:MaxPermSize jdk1.8 以后：-XX:MetaspaceSize -XX:MaxMetaspaceSize 局部变量存在虚拟机栈中，常量存在方法区中，成员变量则随着对象一起存在堆中。 Java 堆从 GC 的角度还可以细分为: 新生代( Eden 区 、 From Survivor 区 和 To Survivor 区 )和老年代。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://luckzp.github.io/tags/JVM/"}]}]